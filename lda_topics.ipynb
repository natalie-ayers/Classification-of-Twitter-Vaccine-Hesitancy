{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd0cda595cc091c472e9dda46637922ba357e006ec97741f8a0b4e3fc352369fe49",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# LDA for COVID-19 Tweet Topic Identification\n",
    "\n",
    "This notebook to identify the primary topics in COVID-19 vaccine tweets is based on a variety of guides written by others:\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/; \n",
    "https://thinkinfi.com/guide-to-build-best-lda-model-using-gensim-python/; https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First, we load in the packages we'll need - we'll primarily be using Gensim and the Gensim wrapper for Mallet for our LDA. We'll also load in our pre-processed, labeled data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/pylab/config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "tweets = os.listdir('data/labeled')\n",
    "tweets_dfs = []\n",
    "for tweet in tweets:\n",
    "    tw_file = 'data/labeled/' + tweet\n",
    "    df = pd.read_json(tw_file)\n",
    "    tweets_dfs.append(df) \n",
    "tweets_clean = pd.concat(tweets_dfs)"
   ]
  },
  {
   "source": [
    "Filter to include only tweets which are negative or neutral, in order to better identify topics related to vaccine hesitancy."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "tweets_negneut = tweets_clean[tweets_clean['score']<=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "    Size of combined df:\t(17075, 8)\n",
      "    First five rows:\n",
      "\n",
      "                     created_at  \\\n",
      "2 2021-05-01 04:01:04+00:00   \n",
      "3 2021-05-01 04:01:40+00:00   \n",
      "4 2021-05-01 04:01:06+00:00   \n",
      "5 2021-05-01 04:01:56+00:00   \n",
      "7 2021-05-01 04:01:08+00:00   \n",
      "\n",
      "                                            text_cln  \\\n",
      "2  appointments available roxbury covid  vaccinat...   \n",
      "3  im afraid childs future federally run schools ...   \n",
      "4  indonesia approves sinopharm covid  vaccine em...   \n",
      "5  thread viral people know culprits anti vaccine...   \n",
      "7  bmc carry token covid  vaccination people age ...   \n",
      "\n",
      "                                        text_cln_tok  positive  neutral  \\\n",
      "2  ['appointments', 'available', 'roxbury', 'site...     0.000    1.000   \n",
      "3  ['afraid', 'childs', 'future', 'federally', 'r...     0.000    0.895   \n",
      "4  ['indonesia', 'approves', 'sinopharm', 'emerge...     0.239    0.531   \n",
      "5  ['thread', 'viral', 'people', 'know', 'culprit...     0.000    0.583   \n",
      "7  ['bmc', 'carry', 'token', 'people', 'age', 'gr...     0.000    1.000   \n",
      "\n",
      "   negative  compound  score  \n",
      "2     0.000    0.0000      0  \n",
      "3     0.105   -0.4023     -1  \n",
      "4     0.230    0.0258      0  \n",
      "5     0.417   -0.5106     -1  \n",
      "7     0.000    0.0000      0  \n",
      "\n",
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "    Size of combined df:\\t{}\n",
    "    First five rows:\n",
    "\n",
    "    {}\n",
    "\"\"\".format(\n",
    "    tweets_negneut.shape,\n",
    "    tweets_negneut.head()\n",
    ")\n",
    ")\n"
   ]
  },
  {
   "source": [
    "First (if desired), we can perform a grid search of possible parameters for both the Gensim and Mallet LDA models to identify the most promising. To do this, use the function choose_lda_models() in pipeline.py with the text_cln_tok column of the full tweets dataframe. In order to successfully run pipeline (for the Mallet LDA model), you'll need to download the Mallet LDA (download with: wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip), unzip it, and re-assign the variable MALLET_PATH in pipeline.py to be the file path where the ballet-2.0.8/bin/mallet files are located (eg, MALLET_PATH = '/usr/lib/mallet-2.0.8/bin/mallet'). You also need to insure all packages used in pipeline.py are installed. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Note on grid search: currently, the parameters to search through are hard-coded in pipeline.py. To search through different parameters, you'll need to adjust the parameter values in choose_lda_models. The initial step of creating a dictionary and corpus to use in the LDA models also takes parameters, which are currently hard-coded to not consider words which appear less than 50 times, words which appear in more than 80 % of the documents, and to filter for only the top 1000000 words. This can also be changed in pipeline.py when build_corpus_dict is called by choose_lda_models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'pipeline' from '/mnt/c/Users/natra/Documents/Education/UChicago/MLforPP/ml-for-pp_vaccine-hesitancy/pipeline.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "#import pipeline\n",
    "import importlib\n",
    "importlib.reload(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_exp2 = pipeline.choose_lda_models(tweets_negneut['text_cln_tok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      ": GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 0.3, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.120891\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 0.3, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.284752\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 0.6, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.164481\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 0.6, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.254130\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 0.6, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.190248\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 0.6, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.181296\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 0.6, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.263923\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'symmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.273235\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'symmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.309026\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'symmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.328953\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'symmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.437971\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'symmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.263733\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'asymmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.277234\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'asymmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.047069\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'asymmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.988778\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'asymmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.269940\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 3, 'alpha': 'asymmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.374701\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.1, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.626884\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.1, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.875524\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.1, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.936752\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.1, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:21.043611\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.1, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.838749\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.3, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.499342\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.3, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.857931\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.3, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.814712\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.3, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.833968\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.3, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.622949\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.6, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.870539\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.6, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.581940\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.6, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.739993\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.6, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.971120\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 0.6, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.870906\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'symmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.606341\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'symmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.797846\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'symmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.825917\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'symmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.942091\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'symmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.776100\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'asymmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.899274\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'asymmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.854197\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'asymmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.695128\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'asymmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:21.045589\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 5, 'alpha': 'asymmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:21.076743\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.1, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.066968\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.1, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.180396\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.1, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.804096\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.1, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.915047\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.1, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.861501\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.3, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.345175\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.3, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.853598\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.3, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.066837\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.3, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.800372\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.3, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.095635\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.6, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.941265\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.6, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.965421\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.6, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.155157\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.6, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.036425\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 0.6, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.970603\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'symmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.900796\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'symmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.716695\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'symmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.754724\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'symmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.147386\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'symmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.034634\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'asymmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.784636\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'asymmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.955657\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'asymmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.110546\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'asymmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:20.034595\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 10, 'alpha': 'asymmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.982869\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.1, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.495366\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.1, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.486816\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.1, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.540510\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.1, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.509130\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.1, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.404447\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.3, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.622410\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.3, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.522786\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.3, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.340872\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.3, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.522544\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.3, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.637069\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.6, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.396352\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.6, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.331553\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.6, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.625298\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.6, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.366199\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 0.6, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.370471\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'symmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.337585\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'symmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.736348\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'symmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.484523\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'symmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.536876\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'symmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.694575\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'asymmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.566130\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'asymmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.528667\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'asymmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.564432\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'asymmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.540583\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 15, 'alpha': 'asymmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.806364\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.1, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.602640\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.1, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.893010\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.1, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.083363\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.1, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.021102\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.1, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.918090\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.3, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.906327\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.3, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.070693\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.3, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.156478\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.3, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.161742\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.3, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.028998\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.6, 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.429413\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.6, 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.936344\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.6, 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.001844\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.6, 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.216643\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 0.6, 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.153687\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'symmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.024819\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'symmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.119648\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'symmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.794723\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'symmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.784947\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'symmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.996708\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'asymmetric', 'eta': 0.1, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.894813\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'asymmetric', 'eta': 0.3, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.989583\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'asymmetric', 'eta': 0.6, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.925017\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'asymmetric', 'eta': 0.9, 'random_state': 100}\n",
      "Time Elapsed: 0:00:18.893722\n",
      "Training model: GensimLDA | {'chunksize': 2000, 'num_topics': 20, 'alpha': 'asymmetric', 'eta': 'symmetric', 'random_state': 100}\n",
      "Time Elapsed: 0:00:19.206310\n",
      "Training model: MalletLDA | {'num_topics': 3, 'alpha': 0.1, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.120912\n",
      "Training model: MalletLDA | {'num_topics': 3, 'alpha': 0.3, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.884453\n",
      "Training model: MalletLDA | {'num_topics': 3, 'alpha': 0.6, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.643841\n",
      "Training model: MalletLDA | {'num_topics': 3, 'alpha': 'symmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:41.170226\n",
      "Training model: MalletLDA | {'num_topics': 3, 'alpha': 'asymmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.948979\n",
      "Training model: MalletLDA | {'num_topics': 5, 'alpha': 0.1, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.660347\n",
      "Training model: MalletLDA | {'num_topics': 5, 'alpha': 0.3, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:41.368557\n",
      "Training model: MalletLDA | {'num_topics': 5, 'alpha': 0.6, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.733066\n",
      "Training model: MalletLDA | {'num_topics': 5, 'alpha': 'symmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:41.608358\n",
      "Training model: MalletLDA | {'num_topics': 5, 'alpha': 'asymmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.680386\n",
      "Training model: MalletLDA | {'num_topics': 10, 'alpha': 0.1, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:41.038796\n",
      "Training model: MalletLDA | {'num_topics': 10, 'alpha': 0.3, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.714724\n",
      "Training model: MalletLDA | {'num_topics': 10, 'alpha': 0.6, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.961679\n",
      "Training model: MalletLDA | {'num_topics': 10, 'alpha': 'symmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:41.020439\n",
      "Training model: MalletLDA | {'num_topics': 10, 'alpha': 'asymmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.650829\n",
      "Training model: MalletLDA | {'num_topics': 15, 'alpha': 0.1, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.827344\n",
      "Training model: MalletLDA | {'num_topics': 15, 'alpha': 0.3, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:41.048490\n",
      "Training model: MalletLDA | {'num_topics': 15, 'alpha': 0.6, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.785208\n",
      "Training model: MalletLDA | {'num_topics': 15, 'alpha': 'symmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.807366\n",
      "Training model: MalletLDA | {'num_topics': 15, 'alpha': 'asymmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.800526\n",
      "Training model: MalletLDA | {'num_topics': 20, 'alpha': 0.1, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.712727\n",
      "Training model: MalletLDA | {'num_topics': 20, 'alpha': 0.3, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.831577\n",
      "Training model: MalletLDA | {'num_topics': 20, 'alpha': 0.6, 'random_seed': 100}\n",
      "Time Elapsed: 0:00:41.065463\n",
      "Training model: MalletLDA | {'num_topics': 20, 'alpha': 'symmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.901174\n",
      "Training model: MalletLDA | {'num_topics': 20, 'alpha': 'asymmetric', 'random_seed': 100}\n",
      "Time Elapsed: 0:00:40.833562\n"
     ]
    }
   ],
   "source": [
    "results_exp = pipeline.choose_lda_models(tweets_negneut['text_cln_tok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     LDA Model                                             Params  \\\n",
       "151  GensimLDA  {'chunksize': 1000, 'num_topics': 5, 'alpha': ...   \n",
       "163  GensimLDA  {'chunksize': 1000, 'num_topics': 5, 'alpha': ...   \n",
       "173  GensimLDA  {'chunksize': 1000, 'num_topics': 5, 'alpha': ...   \n",
       "172  GensimLDA  {'chunksize': 1000, 'num_topics': 5, 'alpha': ...   \n",
       "171  GensimLDA  {'chunksize': 1000, 'num_topics': 5, 'alpha': ...   \n",
       "..         ...                                                ...   \n",
       "147  GensimLDA  {'chunksize': 1000, 'num_topics': 3, 'alpha': ...   \n",
       "148  GensimLDA  {'chunksize': 1000, 'num_topics': 3, 'alpha': ...   \n",
       "149  GensimLDA  {'chunksize': 1000, 'num_topics': 3, 'alpha': ...   \n",
       "126  GensimLDA  {'chunksize': 1000, 'num_topics': 3, 'alpha': ...   \n",
       "127  GensimLDA  {'chunksize': 1000, 'num_topics': 3, 'alpha': ...   \n",
       "\n",
       "              Time Elapsed  Coherence Perplexity  \\\n",
       "151 0 days 00:00:18.660695   0.481878  -5.901042   \n",
       "163 0 days 00:00:18.176696   0.481878  -5.901042   \n",
       "173 0 days 00:00:18.843764   0.481878  -5.901042   \n",
       "172 0 days 00:00:19.690805   0.481878  -5.901042   \n",
       "171 0 days 00:00:20.158660   0.481878  -5.901042   \n",
       "..                     ...        ...        ...   \n",
       "147 0 days 00:00:18.093882   0.331503  -5.955754   \n",
       "148 0 days 00:00:18.248764   0.331503  -5.955754   \n",
       "149 0 days 00:00:18.344837   0.331503  -5.955754   \n",
       "126 0 days 00:00:18.057247   0.331503  -5.955754   \n",
       "127 0 days 00:00:17.637966   0.331503  -5.955754   \n",
       "\n",
       "                                                Topics  \n",
       "151  [(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...  \n",
       "163  [(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...  \n",
       "173  [(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...  \n",
       "172  [(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...  \n",
       "171  [(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...  \n",
       "..                                                 ...  \n",
       "147  [(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...  \n",
       "148  [(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...  \n",
       "149  [(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...  \n",
       "126  [(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...  \n",
       "127  [(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...  \n",
       "\n",
       "[400 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LDA Model</th>\n      <th>Params</th>\n      <th>Time Elapsed</th>\n      <th>Coherence</th>\n      <th>Perplexity</th>\n      <th>Topics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>151</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 5, 'alpha': ...</td>\n      <td>0 days 00:00:18.660695</td>\n      <td>0.481878</td>\n      <td>-5.901042</td>\n      <td>[(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 5, 'alpha': ...</td>\n      <td>0 days 00:00:18.176696</td>\n      <td>0.481878</td>\n      <td>-5.901042</td>\n      <td>[(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 5, 'alpha': ...</td>\n      <td>0 days 00:00:18.843764</td>\n      <td>0.481878</td>\n      <td>-5.901042</td>\n      <td>[(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 5, 'alpha': ...</td>\n      <td>0 days 00:00:19.690805</td>\n      <td>0.481878</td>\n      <td>-5.901042</td>\n      <td>[(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...</td>\n    </tr>\n    <tr>\n      <th>171</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 5, 'alpha': ...</td>\n      <td>0 days 00:00:20.158660</td>\n      <td>0.481878</td>\n      <td>-5.901042</td>\n      <td>[(0, 0.083*\"people\" + 0.024*\"fully\" + 0.023*\"n...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 3, 'alpha': ...</td>\n      <td>0 days 00:00:18.093882</td>\n      <td>0.331503</td>\n      <td>-5.955754</td>\n      <td>[(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 3, 'alpha': ...</td>\n      <td>0 days 00:00:18.248764</td>\n      <td>0.331503</td>\n      <td>-5.955754</td>\n      <td>[(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 3, 'alpha': ...</td>\n      <td>0 days 00:00:18.344837</td>\n      <td>0.331503</td>\n      <td>-5.955754</td>\n      <td>[(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...</td>\n    </tr>\n    <tr>\n      <th>126</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 3, 'alpha': ...</td>\n      <td>0 days 00:00:18.057247</td>\n      <td>0.331503</td>\n      <td>-5.955754</td>\n      <td>[(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...</td>\n    </tr>\n    <tr>\n      <th>127</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 3, 'alpha': ...</td>\n      <td>0 days 00:00:17.637966</td>\n      <td>0.331503</td>\n      <td>-5.955754</td>\n      <td>[(0, 0.041*\"people\" + 0.017*\"india\" + 0.017*\"d...</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "results_exp.sort_values('Coherence',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "results_exp.to_csv('lda_models_grid_search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    LDA Model                                             Params  \\\n",
       "11  GensimLDA  {'chunksize': 1000, 'num_topics': 5, 'random_s...   \n",
       "15  MalletLDA                               {'random_seed': 100}   \n",
       "12  GensimLDA  {'chunksize': 1000, 'num_topics': 10, 'random_...   \n",
       "13  GensimLDA  {'chunksize': 1000, 'num_topics': 15, 'random_...   \n",
       "9   GensimLDA  {'chunksize': 500, 'num_topics': 20, 'random_s...   \n",
       "14  GensimLDA  {'chunksize': 1000, 'num_topics': 20, 'random_...   \n",
       "8   GensimLDA  {'chunksize': 500, 'num_topics': 15, 'random_s...   \n",
       "4   GensimLDA  {'chunksize': 100, 'num_topics': 20, 'random_s...   \n",
       "0   GensimLDA  {'chunksize': 100, 'num_topics': 3, 'random_st...   \n",
       "2   GensimLDA  {'chunksize': 100, 'num_topics': 10, 'random_s...   \n",
       "6   GensimLDA  {'chunksize': 500, 'num_topics': 5, 'random_st...   \n",
       "7   GensimLDA  {'chunksize': 500, 'num_topics': 10, 'random_s...   \n",
       "3   GensimLDA  {'chunksize': 100, 'num_topics': 15, 'random_s...   \n",
       "5   GensimLDA  {'chunksize': 500, 'num_topics': 3, 'random_st...   \n",
       "1   GensimLDA  {'chunksize': 100, 'num_topics': 5, 'random_st...   \n",
       "10  GensimLDA  {'chunksize': 1000, 'num_topics': 3, 'random_s...   \n",
       "\n",
       "             Time Elapsed  Coherence Perplexity  \n",
       "11 0 days 00:00:18.326424   0.481878  -5.901042  \n",
       "15 0 days 00:00:40.614905   0.470407        N/A  \n",
       "12 0 days 00:00:19.540925   0.446513  -5.850479  \n",
       "13 0 days 00:00:19.223515   0.420163  -5.922036  \n",
       "9  0 days 00:00:18.387839   0.407586   -8.15214  \n",
       "14 0 days 00:00:19.082389   0.402379  -6.381634  \n",
       "8  0 days 00:00:17.467022   0.399271  -6.284955  \n",
       "4  0 days 00:00:17.142501   0.393271 -15.103237  \n",
       "0  0 days 00:00:16.765448   0.383190  -6.104693  \n",
       "2  0 days 00:00:15.813604   0.380098  -6.110908  \n",
       "6  0 days 00:00:17.724389   0.355522  -5.965964  \n",
       "7  0 days 00:00:17.585107   0.353923  -6.007753  \n",
       "3  0 days 00:00:16.551411   0.353908  -6.702777  \n",
       "5  0 days 00:00:17.551684   0.345657  -5.961161  \n",
       "1  0 days 00:00:15.181398   0.334772  -6.094285  \n",
       "10 0 days 00:00:18.383123   0.331503  -5.955754  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LDA Model</th>\n      <th>Params</th>\n      <th>Time Elapsed</th>\n      <th>Coherence</th>\n      <th>Perplexity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 5, 'random_s...</td>\n      <td>0 days 00:00:18.326424</td>\n      <td>0.481878</td>\n      <td>-5.901042</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>MalletLDA</td>\n      <td>{'random_seed': 100}</td>\n      <td>0 days 00:00:40.614905</td>\n      <td>0.470407</td>\n      <td>N/A</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 10, 'random_...</td>\n      <td>0 days 00:00:19.540925</td>\n      <td>0.446513</td>\n      <td>-5.850479</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 15, 'random_...</td>\n      <td>0 days 00:00:19.223515</td>\n      <td>0.420163</td>\n      <td>-5.922036</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 500, 'num_topics': 20, 'random_s...</td>\n      <td>0 days 00:00:18.387839</td>\n      <td>0.407586</td>\n      <td>-8.15214</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 20, 'random_...</td>\n      <td>0 days 00:00:19.082389</td>\n      <td>0.402379</td>\n      <td>-6.381634</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 500, 'num_topics': 15, 'random_s...</td>\n      <td>0 days 00:00:17.467022</td>\n      <td>0.399271</td>\n      <td>-6.284955</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 100, 'num_topics': 20, 'random_s...</td>\n      <td>0 days 00:00:17.142501</td>\n      <td>0.393271</td>\n      <td>-15.103237</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 100, 'num_topics': 3, 'random_st...</td>\n      <td>0 days 00:00:16.765448</td>\n      <td>0.383190</td>\n      <td>-6.104693</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 100, 'num_topics': 10, 'random_s...</td>\n      <td>0 days 00:00:15.813604</td>\n      <td>0.380098</td>\n      <td>-6.110908</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 500, 'num_topics': 5, 'random_st...</td>\n      <td>0 days 00:00:17.724389</td>\n      <td>0.355522</td>\n      <td>-5.965964</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 500, 'num_topics': 10, 'random_s...</td>\n      <td>0 days 00:00:17.585107</td>\n      <td>0.353923</td>\n      <td>-6.007753</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 100, 'num_topics': 15, 'random_s...</td>\n      <td>0 days 00:00:16.551411</td>\n      <td>0.353908</td>\n      <td>-6.702777</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 500, 'num_topics': 3, 'random_st...</td>\n      <td>0 days 00:00:17.551684</td>\n      <td>0.345657</td>\n      <td>-5.961161</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 100, 'num_topics': 5, 'random_st...</td>\n      <td>0 days 00:00:15.181398</td>\n      <td>0.334772</td>\n      <td>-6.094285</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 3, 'random_s...</td>\n      <td>0 days 00:00:18.383123</td>\n      <td>0.331503</td>\n      <td>-5.955754</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "results_exp.sort_values('Coherence', ascending=False)"
   ]
  },
  {
   "source": [
    "Once the ideal parameters are selected, we can manually create the models to consider specific aspects more in-depth (and to create the dynamic visualizations below). First, we use Gensim to create a dictionary of the unique words that appear mapped to an id. (We are still filtering out from the dictionary words that don't appear enough or appear in too many tweets.) Second, we'll create a corpus of the tweets, which contains the number of times a given word (identified by id) appeared in each tweet. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "tweets_nn_lst = []\n",
    "for tweet in tweets_negneut['text_cln_tok']:\n",
    "    tweets_nn_lst.append(ast.literal_eval(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "single_dict = corpora.Dictionary(tweets_nn_lst)\n",
    "single_dict.filter_extremes(no_below=50, no_above=0.80, keep_n=1000000)\n",
    "\n",
    "single_corpus = [single_dict.doc2bow(tweet) for tweet in tweets_nn_lst]"
   ]
  },
  {
   "source": [
    "To see the dictionary and corpus contents, run the below 2 cells:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'appointments': 0, 'available': 1, 'baptist': 2, 'check': 3, 'sign': 4, 'site': 5, 'cdc': 6, 'control': 7, 'dont': 8, 'future': 9, 'having': 10, 'health': 11, 'run': 12, 'school': 13, 'schools': 14, 'them': 15, 'approves': 16, 'emergency': 17, 'reuters': 18, 'use': 19, 'anti': 20, 'know': 21, 'people': 22, 'thread': 23, 'age': 24, 'centre': 25, 'centres': 26, 'group': 27, 'hospital': 28, 'mumbai': 29, 'today': 30, 'work': 31, 'china': 32, 'meet': 33, 'needs': 34, 'south': 35, 'amid': 36, 'rollout': 37, 'shortage': 38, 'states': 39, 'far': 40, 'injuries': 41, 'help': 42, 'infection': 43, 'receive': 44, 'saw': 45, 'india': 46, 'news': 47, 'mask': 48, 'masks': 49, 'wearing': 50, 'department': 51, 'got': 52, 'pfizer': 53, 'hold': 54, 'line': 55, 'actually': 56, 'biggest': 57, 'like': 58, 'crore': 59, 'details': 60, 'modi': 61, 'population': 62, 'thing': 63, 'usa': 64, 'healthcare': 65, 'supply': 66, 'anxiety': 67, 'caused': 68, 'clinics': 69, 'dozens': 70, 'officials': 71, 'problem': 72, 'reactions': 73, 'shots': 74, 'bbc': 75, 'dies': 76, 'doctor': 77, 'karanja': 78, 'kenyan': 79, 'stephen': 80, 'fact': 81, 'fda': 82, 'wrong': 83, 'country': 84, 'happening': 85, 'short': 86, 'access': 87, 'cards': 88, 'don': 89, 'fake': 90, 'hesitancy': 91, 'online': 92, 'person': 93, 'too': 94, 'understand': 95, 'certificate': 96, 'outbreak': 97, 'mrna': 98, 'read': 99, 'cases': 100, 'tell': 101, 'year': 102, 'doses': 103, 'wont': 104, 'announced': 105, 'calls': 106, 'that': 107, 'worst': 108, 'cdnpoli': 109, 'data': 110, 'dose': 111, 'efficacy': 112, 'experts': 113, 'leaders': 114, 'medical': 115, 'new': 116, 'political': 117, 'this': 118, 'batch': 119, 'likely': 120, 'sputnik': 121, 'adults': 122, 'deadly': 123, 'eligible': 124, 'family': 125, 'center': 126, 'death': 127, 'instead': 128, 'jab': 129, 'received': 130, 'yet': 131, 'getting': 132, 'taking': 133, 'areas': 134, 'highest': 135, 'rates': 136, 'risk': 137, 'fully': 138, 'one': 139, 'drive': 140, 'nation': 141, 'start': 142, 'home': 143, 'now': 144, 'there': 145, 'virus': 146, 'wait': 147, 'world': 148, 'you': 149, 'registration': 150, 'started': 151, 'days': 152, 'second': 153, 'limited': 154, 'modernas': 155, 'live': 156, 'says': 157, 'tested': 158, 'updates': 159, 'number': 160, 'open': 161, 'shot': 162, 'week': 163, 'weeks': 164, 'lockdown': 165, 'not': 166, 'pradesh': 167, 'priority': 168, 'think': 169, 'ages': 170, 'believe': 171, 'called': 172, 'come': 173, 'flu': 174, 'immunity': 175, 'look': 176, 'active': 177, 'deaths': 178, 'discharges': 179, 'hours': 180, 'ministry': 181, 'recoveries': 182, 'reports': 183, 'toll': 184, 'total': 185, 'union': 186, 'doctors': 187, 'low': 188, 'remains': 189, 'study': 190, 'big': 191, 'delay': 192, 'early': 193, 'groups': 194, 'plan': 195, 'science': 196, 'drop': 197, 'heres': 198, 'plans': 199, 'test': 200, 'government': 201, 'private': 202, 'years': 203, 'march': 204, 'program': 205, 'variant': 206, 'face': 207, 'fall': 208, 'govt': 209, 'kashmir': 210, 'past': 211, 'appointment': 212, 'schedule': 213, 'things': 214, 'human': 215, 'gets': 216, 'starts': 217, 'canada': 218, 'federal': 219, 'support': 220, 'working': 221, 'impact': 222, 'day': 223, 'single': 224, 'spike': 225, 'click': 226, 'concerns': 227, 'long': 228, 'term': 229, 'able': 230, 'begin': 231, 'follow': 232, 'here': 233, 'phase': 234, 'saturday': 235, 'april': 236, 'friday': 237, 'making': 238, 'moderna': 239, 'organization': 240, 'who': 241, 'globe': 242, 'leaves': 243, 'mail': 244, 'pfizers': 245, 'recipients': 246, 'variants': 247, 'vulnerable': 248, 'breaking': 249, 'based': 250, 'going': 251, 'wave': 252, 'clinic': 253, 'million': 254, 'money': 255, 'right': 256, 'state': 257, 'aged': 258, 'begins': 259, 'city': 260, 'including': 261, 'york': 262, 'young': 263, 'listing': 264, 'daily': 265, 'lakh': 266, 'doesn': 267, 'drug': 268, 'experimental': 269, 'crisis': 270, 'didn': 271, 'minister': 272, 'again': 273, 'more': 274, 'production': 275, 'receives': 276, 'americans': 277, 'times': 278, 'area': 279, 'high': 280, 'vax': 281, 'real': 282, 'situation': 283, 'stayhome': 284, 'gives': 285, 'update': 286, 'needed': 287, 'body': 288, 'offer': 289, 'trial': 290, 'case': 291, 'latest': 292, 'residents': 293, 'demand': 294, 'australia': 295, 'citizens': 296, 'protect': 297, 'want': 298, 'wants': 299, 'medicine': 300, 'travel': 301, 'america': 302, 'failure': 303, 'first': 304, 'post': 305, 'washington': 306, 'oxygen': 307, 'said': 308, 'higher': 309, 'spread': 310, 'stop': 311, 'forge': 312, 'hill': 313, 'pro': 314, 'sites': 315, 'thehill': 316, 'trump': 317, 'urging': 318, 'borders': 319, 'indias': 320, 'surge': 321, 'story': 322, 'receiving': 323, 'dying': 324, 'lot': 325, 'mass': 326, 'pandemic': 327, 'safe': 328, 'countries': 329, 'millions': 330, 'infected': 331, 'waiting': 332, 'stay': 333, 'western': 334, 'need': 335, 'place': 336, 'man': 337, 'stand': 338, 'indian': 339, 'russia': 340, 'sputnikv': 341, 'fear': 342, 'warning': 343, 'developed': 344, 'fatality': 345, 'misleading': 346, 'rate': 347, 'record': 348, 'possible': 349, 'quickly': 350, 'students': 351, 'ban': 352, 'can': 353, 'campaign': 354, 'given': 355, 'blood': 356, 'out': 357, 'clots': 358, 'normal': 359, 'women': 360, 'negative': 361, 'patent': 362, 'thats': 363, 'time': 364, 'despite': 365, 'poor': 366, 'public': 367, 'evidence': 368, 'finds': 369, 'away': 370, 'covaxin': 371, 'business': 372, 'japan': 373, 'point': 374, 'biden': 375, 'launches': 376, 'produced': 377, 'arrives': 378, 'north': 379, 'adult': 380, 'astrazeneca': 381, 'institute': 382, 'planning': 383, 'serum': 384, 'video': 385, 'numbers': 386, 'register': 387, 'app': 388, 'information': 389, 'present': 390, 'senior': 391, 'locations': 392, 'common': 393, 'county': 394, 'died': 395, 'lives': 396, 'continues': 397, 'starting': 398, 'jammu': 399, 'srinagar': 400, 'remember': 401, 'monday': 402, 'team': 403, 'bad': 404, 'global': 405, 'mean': 406, 'over': 407, 'effects': 408, 'delhi': 409, 'set': 410, 'end': 411, 'order': 412, 'let': 413, 'course': 414, 'key': 415, 'cause': 416, 'effort': 417, 'restrictions': 418, 'fight': 419, 'youre': 420, 'gujarat': 421, 'maharashtra': 422, 'list': 423, 'website': 424, 'die': 425, 'may': 426, 'patients': 427, 'jabs': 428, 'pace': 429, 'efforts': 430, 'following': 431, 'illness': 432, 'local': 433, 'according': 434, 'reported': 435, 'report': 436, 'required': 437, 'turn': 438, 'media': 439, 'members': 440, 'half': 441, 'politics': 442, 'chinese': 443, 'allowed': 444, 'social': 445, 'treatment': 446, 'russias': 447, 'card': 448, 'remove': 449, 'fauci': 450, 'tracker': 451, 'listen': 452, 'saying': 453, 'unnecessary': 454, 'they': 455, 'college': 456, 'company': 457, 'produce': 458, 'cancer': 459, 'herd': 460, 'disease': 461, 'prevent': 462, 'protection': 463, 'severe': 464, 'adverse': 465, 'percent': 466, 'kill': 467, 'centers': 468, 'food': 469, 'animals': 470, 'central': 471, 'karnataka': 472, 'watch': 473, 'shortages': 474, 'important': 475, 'laws': 476, 'passports': 477, 'refusing': 478, 'administered': 479, 'foreign': 480, 'hospitals': 481, 'johnson': 482, 'national': 483, 'town': 484, 'workers': 485, 'clinical': 486, 'arrive': 487, 'steps': 488, 'humanity': 489, 'left': 490, 'currently': 491, 'action': 492, 'patents': 493, 'care': 494, 'soon': 495, 'worse': 496, 'bjp': 497, 'testing': 498, 'matters': 499, 'questions': 500, 'yesterday': 501, 'thought': 502, 'administration': 503, 'months': 504, 'sick': 505, 'happen': 506, 'ask': 507, 'buy': 508, 'makes': 509, 'date': 510, 'event': 511, 'biontech': 512, 'trials': 513, 'article': 514, 'immune': 515, 'close': 516, 'book': 517, 'ontario': 518, 'toronto': 519, 'life': 520, 'ill': 521, 'all': 522, 'dangerous': 523, 'old': 524, 'roll': 525, 'approve': 526, 'requiring': 527, 'research': 528, 'district': 529, 'current': 530, 'israel': 531, 'chief': 532, 'good': 533, 'russian': 534, 'seeking': 535, 'ahead': 536, 'official': 537, 'way': 538, 'administering': 539, 'infections': 540, 'brazil': 541, 'philippines': 542, 'warned': 543, 'black': 544, 'spreading': 545, 'jesus': 546, 'reach': 547, 'visit': 548, 'issues': 549, 'near': 550, 'house': 551, 'require': 552, 'white': 553, 'result': 554, 'the': 555, 'rise': 556, 'link': 557, 'month': 558, 'lack': 559, 'shows': 560, 'avoid': 561, 'tomorrow': 562, 'reason': 563, 'distancing': 564, 'looking': 565, 'stupid': 566, 'cure': 567, 'scientists': 568, 'positive': 569, 'covishield': 570, 'what': 571, 'community': 572, 'took': 573, 'walk': 574, 'issue': 575, 'reading': 576, 'coming': 577, 'forced': 578, 'beds': 579, 'told': 580, 'hit': 581, 'continue': 582, 'proof': 583, 'president': 584, 'response': 585, 'nearly': 586, 'abandoned': 587, 'dead': 588, 'european': 589, 'ppl': 590, 'children': 591, 'later': 592, 'providing': 593, 'ego': 594, 'ennaid': 595, 'love': 596, 'prevailed': 597, 'racism': 598, 'therapeutics': 599, 'holding': 600, 'passed': 601, 'related': 602, 'measures': 603, 'wear': 604, 'park': 605, 'ceo': 606, 'produces': 607, 'florida': 608, 'provide': 609, 'heart': 610, 'transmission': 611, 'offering': 612, 'closed': 613, 'arrived': 614, 'europe': 615, 'killed': 616, 'morning': 617, 'hot': 618, 'spot': 619, 'american': 620, 'symptoms': 621, 'administers': 622, 'distribute': 623, 'opens': 624, 'medicines': 625, 'pressure': 626, 'distribution': 627, 'trudeau': 628, 'older': 629, 'interview': 630, 'hyderabad': 631, 'truck': 632, 'sold': 633, 'ward': 634, 'explore': 635, 'mln': 636, 'maryland': 637, 'tough': 638, 'canadians': 639, 'gene': 640, 'therapy': 641, 'cvs': 642, 'appts': 643, 'often': 644, 'quantities': 645, 'means': 646, 'vhcon': 647, 'poonawalla': 648, 'ford': 649, 'adar': 650, 'farm': 651, 'kvax': 652}\n",
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(single_dict.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]\n",
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(single_corpus[0])"
   ]
  },
  {
   "source": [
    "Next, we can train the model with the parameters we identified above (or, with any other parameters)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "single_model = gensim.models.ldamodel.LdaModel(corpus=single_corpus,\n",
    "                                           id2word=single_dict,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=1000,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.1,\n",
    "                                           eta=1,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.063*\"people\" + 0.023*\"fully\" + 0.018*\"virus\" + 0.017*\"dose\" + 0.017*\"nation\" + 0.016*\"situation\" + 0.015*\"getting\" + 0.013*\"time\" + 0.012*\"shot\" + 0.012*\"times\"'),\n",
       " (1,\n",
       "  '0.068*\"cases\" + 0.048*\"total\" + 0.034*\"new\" + 0.032*\"india\" + 0.025*\"doses\" + 0.025*\"deaths\" + 0.022*\"health\" + 0.022*\"death\" + 0.018*\"reports\" + 0.017*\"recoveries\"'),\n",
       " (2,\n",
       "  '0.043*\"india\" + 0.020*\"fight\" + 0.018*\"research\" + 0.017*\"center\" + 0.015*\"appointment\" + 0.015*\"oxygen\" + 0.015*\"australia\" + 0.015*\"wrong\" + 0.014*\"supply\" + 0.014*\"global\"'),\n",
       " (3,\n",
       "  '0.132*\"available\" + 0.111*\"appointments\" + 0.106*\"near\" + 0.105*\"sign\" + 0.103*\"cvs\" + 0.041*\"pfizer\" + 0.024*\"johnson\" + 0.015*\"variants\" + 0.012*\"canada\" + 0.010*\"health\"'),\n",
       " (4,\n",
       "  '0.059*\"immunity\" + 0.049*\"you\" + 0.038*\"fake\" + 0.033*\"die\" + 0.032*\"company\" + 0.032*\"medicine\" + 0.031*\"wait\" + 0.029*\"usa\" + 0.026*\"mask\" + 0.025*\"cure\"')]"
      ]
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "# View the topics identified in the above model\n",
    "single_model.print_topics()"
   ]
  },
  {
   "source": [
    "We can use Coherence as one method for considering our model's accuracy:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  \n",
      "0.49433827902219873\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "single_coherence_model_lda = CoherenceModel(model=single_model, texts=tweets_nn_lst, dictionary=single_dict, coherence='c_v')\n",
    "single_coherence_lda = single_coherence_model_lda.get_coherence()\n",
    "print(single_coherence_lda)"
   ]
  },
  {
   "source": [
    "We can also visualize the topics and their overlap:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.347104 -0.270027       1        1  21.493818\n",
       "0      0.235138 -0.113997       2        1  18.678340\n",
       "2      0.012179  0.129301       3        1  18.054852\n",
       "1      0.228433 -0.177726       4        1  15.699520\n",
       "5     -0.063569  0.161599       5        1  15.486252\n",
       "4     -0.065077  0.270850       6        1  10.587218, topic_info=             Term         Freq        Total Category  logprob  loglift\n",
       "22         people  2828.000000  2828.000000  Default  30.0000  30.0000\n",
       "1       available  2638.000000  2638.000000  Default  29.0000  29.0000\n",
       "0    appointments  2389.000000  2389.000000  Default  28.0000  28.0000\n",
       "550          near  2360.000000  2360.000000  Default  27.0000  27.0000\n",
       "4            sign  2325.000000  2325.000000  Default  26.0000  26.0000\n",
       "..            ...          ...          ...      ...      ...      ...\n",
       "133        taking   107.510772   108.402962   Topic6  -4.6140   2.2373\n",
       "266          lakh   104.460851   105.362945   Topic6  -4.6428   2.2369\n",
       "540    infections   102.652038   103.545210   Topic6  -4.6603   2.2369\n",
       "204         march   102.509339   103.401968   Topic6  -4.6617   2.2369\n",
       "476          laws   276.449312   292.496050   Topic6  -3.6696   2.1891\n",
       "\n",
       "[213 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "87        4  0.996178        access\n",
       "434       3  0.995897     according\n",
       "177       6  0.996760        active\n",
       "479       4  0.996811  administered\n",
       "622       4  0.997940   administers\n",
       "...     ...       ...           ...\n",
       "148       5  0.997105         world\n",
       "83        1  0.995938         wrong\n",
       "102       6  0.996099          year\n",
       "149       3  0.997375           you\n",
       "263       3  0.997551         young\n",
       "\n",
       "[189 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 2, 6, 5])"
      ],
      "text/html": "\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n\n\n<div id=\"ldavis_el19731397749451037602771054418\"></div>\n<script type=\"text/javascript\">\n\nvar ldavis_el19731397749451037602771054418_data = {\"mdsDat\": {\"x\": [-0.3471043460376804, 0.23513812647986368, 0.012179097992583416, 0.22843271946455693, -0.06356884384769389, -0.06507675405162956], \"y\": [-0.27002684721079884, -0.1139974620268362, 0.12930083808831133, -0.17772581548581112, 0.16159919146942556, 0.2708500951657097], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [21.493818268958382, 18.678339604352335, 18.05485156589462, 15.699519894652322, 15.486252271476515, 10.587218394665827]}, \"tinfo\": {\"Term\": [\"people\", \"available\", \"appointments\", \"near\", \"sign\", \"cvs\", \"india\", \"cases\", \"new\", \"health\", \"total\", \"situation\", \"doses\", \"fully\", \"time\", \"nation\", \"pfizer\", \"deaths\", \"death\", \"dose\", \"getting\", \"virus\", \"times\", \"news\", \"need\", \"going\", \"soon\", \"lack\", \"modi\", \"million\", \"available\", \"appointments\", \"near\", \"sign\", \"cvs\", \"canada\", \"risk\", \"johnson\", \"says\", \"future\", \"cdc\", \"check\", \"wrong\", \"appointment\", \"rate\", \"disease\", \"variants\", \"workers\", \"shows\", \"high\", \"doesn\", \"study\", \"research\", \"latest\", \"vax\", \"trump\", \"ages\", \"sites\", \"based\", \"developed\", \"nation\", \"pfizer\", \"dose\", \"getting\", \"need\", \"going\", \"black\", \"govt\", \"today\", \"second\", \"shot\", \"present\", \"days\", \"tested\", \"drive\", \"data\", \"saturday\", \"weeks\", \"said\", \"age\", \"experts\", \"live\", \"start\", \"adults\", \"think\", \"now\", \"group\", \"here\", \"trials\", \"update\", \"farm\", \"news\", \"india\", \"situation\", \"time\", \"soon\", \"modi\", \"fight\", \"pandemic\", \"tough\", \"global\", \"outbreak\", \"you\", \"indian\", \"public\", \"stop\", \"countries\", \"mass\", \"spread\", \"way\", \"according\", \"effects\", \"read\", \"life\", \"china\", \"possible\", \"coming\", \"biden\", \"die\", \"young\", \"daily\", \"continue\", \"people\", \"doses\", \"lack\", \"know\", \"country\", \"government\", \"anti\", \"administered\", \"dont\", \"doctor\", \"mask\", \"access\", \"states\", \"oxygen\", \"don\", \"dies\", \"like\", \"months\", \"children\", \"hospitals\", \"administers\", \"fake\", \"blood\", \"want\", \"long\", \"testing\", \"shots\", \"wear\", \"reactions\", \"kenyan\", \"health\", \"fully\", \"times\", \"million\", \"world\", \"dying\", \"food\", \"use\", \"stand\", \"americans\", \"passed\", \"australia\", \"moderna\", \"population\", \"emergency\", \"received\", \"county\", \"supply\", \"positive\", \"astrazeneca\", \"work\", \"sick\", \"center\", \"died\", \"april\", \"jab\", \"centre\", \"masks\", \"mrna\", \"city\", \"cases\", \"new\", \"total\", \"deaths\", \"death\", \"virus\", \"reports\", \"state\", \"got\", \"hours\", \"recoveries\", \"toll\", \"active\", \"year\", \"immunity\", \"ministry\", \"union\", \"discharges\", \"dead\", \"day\", \"right\", \"look\", \"reported\", \"wait\", \"flu\", \"spike\", \"taking\", \"lakh\", \"infections\", \"march\", \"laws\"], \"Freq\": [2828.0, 2638.0, 2389.0, 2360.0, 2325.0, 2317.0, 1914.0, 1243.0, 983.0, 965.0, 768.0, 905.0, 835.0, 740.0, 753.0, 728.0, 701.0, 519.0, 500.0, 663.0, 628.0, 457.0, 542.0, 730.0, 539.0, 538.0, 527.0, 459.0, 494.0, 446.0, 2637.7353808367484, 2388.2918290007246, 2359.6473445334977, 2324.992061373677, 2316.215730888246, 299.96838291566854, 292.5703064540705, 261.02809232724877, 253.99127330017558, 289.4365033156893, 210.99790604256876, 207.06105110948465, 207.95052577271377, 198.2707748360619, 188.02355337921105, 188.70976818245853, 179.1838721009759, 178.11377897474017, 177.84833730712415, 168.69784953327584, 166.17330300778997, 158.44365518242907, 144.78518118594982, 128.49905412114768, 127.10398311767764, 122.70897828629266, 121.23878460427227, 114.36012721983641, 112.53754603462416, 110.65010668099376, 727.1764806612885, 701.1547197292915, 662.3118836808006, 628.1377245671613, 538.7891642497315, 538.0979876239588, 439.60027479746105, 421.0995107398539, 417.4437349537095, 413.5041957145315, 386.36534564573316, 358.8268884833585, 329.6796304853256, 292.2398391447908, 280.7005115335555, 272.8445126728152, 270.70721532690305, 262.80382750613154, 255.19616176651743, 230.61551354496882, 220.49081500574397, 218.25569216091824, 214.6873337681372, 208.17784791876824, 204.86288412310017, 203.35242562721322, 202.78261749253207, 194.48963859756657, 186.17393652695617, 176.78650256034143, 341.7916355891078, 625.2409206696549, 1914.1291593795763, 904.778466870277, 753.1483744772229, 526.2827241743305, 493.9312633793548, 447.9131954839935, 385.9898468793757, 389.8132843407073, 332.36655941176474, 330.3752338265657, 288.94052928891557, 273.94086483933387, 264.4044253550006, 260.87185180449757, 248.57615019427547, 247.3264552274827, 215.7462902756495, 213.5651727154683, 211.0287960005188, 194.39284116700946, 189.56007974977064, 188.09662978383304, 187.34788433510383, 187.80485283182497, 184.62617748791706, 177.57431255199327, 174.71744115586307, 171.59444409670985, 169.2953374980742, 169.93508650260696, 2827.2769676852577, 834.5133224426725, 458.1874345383925, 418.23954792296075, 388.77409839711083, 368.2867213450998, 330.963241389494, 288.0762518020511, 259.87123530647045, 254.56199334423704, 246.02925629809027, 239.06612103636337, 227.69779165782842, 227.29204792630463, 217.76797555324427, 213.44392718677457, 205.00508372806013, 204.88485559584385, 194.5600812388283, 186.06894318634772, 184.5397420090282, 172.8451668677798, 169.71776740661352, 168.52998656189723, 163.20025218938818, 155.35621292278833, 152.17602453339748, 149.28866190136569, 147.18194325814363, 145.6963633518201, 964.8954767285944, 739.7060504766035, 541.6979988995481, 445.3387312694357, 433.4119485791834, 405.5900490774402, 409.2457453771969, 394.14952621464437, 374.48531946306923, 357.89388236140394, 365.9579522154141, 343.11928503562115, 337.2112310872929, 315.211180360869, 304.2728166683746, 282.74466316601934, 272.2461615904487, 247.8304007664277, 239.96087621715478, 235.99678290576432, 229.97000105803124, 205.7706249706479, 204.98533633170976, 203.6985091287894, 199.2663013366094, 194.52334709458708, 182.45454899161797, 178.53147480266034, 176.75534384605103, 166.5291850102352, 1242.6956579633415, 982.1104884599673, 767.8254931828751, 518.269198690188, 499.52498836237896, 457.0697938263668, 346.5236072673206, 309.95567042594604, 271.780301346972, 269.9134930951658, 260.23299756821, 260.02504015161634, 244.90362864258373, 244.06355583757392, 240.2189196114139, 211.47406479878026, 207.75877311561382, 225.2109522774686, 197.07471586738706, 186.32220824245582, 177.62618187302084, 165.83773598352786, 121.07701840676323, 117.62618398625133, 116.41884702901764, 108.77924554810492, 107.5107719793282, 104.46085109191424, 102.65203776523502, 102.50933852950187, 276.4493120479472], \"Total\": [2828.0, 2638.0, 2389.0, 2360.0, 2325.0, 2317.0, 1914.0, 1243.0, 983.0, 965.0, 768.0, 905.0, 835.0, 740.0, 753.0, 728.0, 701.0, 519.0, 500.0, 663.0, 628.0, 457.0, 542.0, 730.0, 539.0, 538.0, 527.0, 459.0, 494.0, 446.0, 2638.623456616976, 2389.179456368598, 2360.5350535331922, 2325.8796300724275, 2317.103271527123, 300.8634506131959, 293.4685003859281, 261.91687584541984, 254.88322127256748, 290.4612010829543, 211.89094039599328, 207.95080029712975, 208.84833688671995, 199.1616767673403, 188.91700691802407, 189.60992858701715, 180.07721137618438, 179.01032919347932, 178.74749677736668, 169.5977739821312, 167.08325560701792, 159.3375449071675, 145.6999354768229, 129.40225205670498, 127.9990400510728, 123.60219581433432, 122.13620096921267, 115.24992690045568, 113.43833956707411, 111.54270869654013, 728.0289088683152, 701.9938802356934, 663.1507703793364, 628.9782549316587, 539.630138067041, 538.941291932736, 440.4481618442043, 421.9459604833853, 418.28492088085585, 414.34364496363514, 387.20483815430845, 359.6846427394873, 330.52103792596137, 293.08187173866486, 281.5404508485483, 273.6850014487005, 271.54977357774004, 263.64612741977936, 256.03620078783314, 231.4541556742244, 221.33470152449414, 219.09539505582626, 215.529134772338, 209.01621048186695, 205.70410331295312, 204.1922375110611, 203.6209851151362, 195.32962228278078, 187.01784642578835, 177.628718091046, 366.32216166078393, 730.8427303874748, 1914.9588767358082, 905.6127755001618, 753.9733823460352, 527.1130038605539, 494.7595337894396, 448.7362038940716, 386.8116846012245, 390.65541465083186, 333.18705900834834, 331.19775902963136, 289.76064507603616, 274.76135799518465, 265.22763898222206, 261.69603171554826, 249.3991714206605, 248.15194374656136, 216.56796591668657, 214.3890577874633, 211.8693095326026, 195.21554827337377, 190.38638198866298, 188.92256853573676, 188.1711451552285, 188.6307083543652, 185.45236769446706, 178.39894883887405, 175.53790210820335, 172.42232311077706, 170.11771077105016, 170.76170498627798, 2828.1255301209458, 835.3568499203187, 459.0474944779674, 419.08511105820423, 389.61967803124526, 369.131552557967, 331.8050652354794, 288.92146916625427, 260.7169139334249, 255.40425995864953, 246.8728214840617, 239.91697977304997, 228.54145883386414, 228.13697611231277, 218.61189478354572, 214.28461230868504, 205.84862893195609, 205.7338368868006, 195.4049449032379, 186.91261358137166, 185.38188426569337, 173.69439869307223, 170.56266375281956, 169.37390759338422, 164.0456837459648, 156.2030074681691, 153.02066100366582, 150.13176458241415, 148.02550432296445, 146.53597740524913, 965.7512690695, 740.5512772739859, 542.5464487506828, 446.18211529036967, 434.25730750256565, 406.4415662810131, 410.11397782372046, 394.9919800320634, 375.36103236040964, 358.7368476544979, 366.82775342100047, 343.96749553275043, 338.05300073851544, 316.0564600834391, 305.11447399589684, 283.5889399292422, 273.08992049138584, 248.6760352697824, 240.80327177509238, 236.84103486721412, 230.8179664857244, 206.6221980214593, 205.83375649928988, 204.542582869413, 200.11199541525914, 195.36753415615917, 183.30293516344184, 179.37922035996488, 177.60053881337706, 167.37384107552177, 1243.5867229404441, 983.0016098793018, 768.7182090649632, 519.1588087510074, 500.41861543456974, 457.9623691353145, 347.41396377986325, 310.85049602268, 272.6738431697869, 270.8050096073757, 261.1267131739568, 260.93012884711305, 245.79646451637566, 244.95555513218193, 241.1108643045887, 212.36608614719677, 208.65401638161717, 226.18631312847825, 197.96552788984474, 187.21423804777265, 178.51956429582305, 166.73170833171392, 121.96858926151633, 118.51774717602585, 117.3095011131604, 109.66993202587582, 108.40296245828121, 105.36294546299075, 103.54521049054405, 103.40196812556495, 292.4960497305497], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.1221, -2.2214, -2.2335, -2.2483, -2.2521, -4.2961, -4.321, -4.4351, -4.4624, -4.3318, -4.6479, -4.6667, -4.6624, -4.7101, -4.7632, -4.7595, -4.8113, -4.8173, -4.8188, -4.8716, -4.8867, -4.9343, -5.0245, -5.1438, -5.1547, -5.1899, -5.202, -5.2604, -5.2765, -5.2934, -3.2702, -3.3066, -3.3636, -3.4166, -3.57, -3.5713, -3.7735, -3.8165, -3.8252, -3.8347, -3.9026, -3.9765, -4.0612, -4.1818, -4.2221, -4.2504, -4.2583, -4.2879, -4.3173, -4.4186, -4.4635, -4.4737, -4.4902, -4.521, -4.537, -4.5444, -4.5472, -4.589, -4.6327, -4.6844, -4.0251, -3.4212, -2.2684, -3.0177, -3.2011, -3.5596, -3.623, -3.7208, -3.8696, -3.8597, -4.0192, -4.0252, -4.1592, -4.2125, -4.2479, -4.2614, -4.3096, -4.3147, -4.4513, -4.4615, -4.4734, -4.5555, -4.5807, -4.5884, -4.5924, -4.59, -4.6071, -4.646, -4.6622, -4.6803, -4.6937, -4.69, -1.7385, -2.9588, -3.5583, -3.6496, -3.7226, -3.7767, -3.8836, -4.0224, -4.1254, -4.1461, -4.1802, -4.2089, -4.2576, -4.2594, -4.3022, -4.3222, -4.3626, -4.3632, -4.4149, -4.4595, -4.4677, -4.5332, -4.5515, -4.5585, -4.5906, -4.6399, -4.6606, -4.6797, -4.6939, -4.7041, -2.7999, -3.0657, -3.3772, -3.5731, -3.6002, -3.6666, -3.6576, -3.6952, -3.7464, -3.7917, -3.7694, -3.8339, -3.8512, -3.9187, -3.954, -4.0274, -4.0652, -4.1592, -4.1915, -4.2081, -4.234, -4.3452, -4.349, -4.3553, -4.3773, -4.4014, -4.4654, -4.4872, -4.4972, -4.5568, -2.1666, -2.4019, -2.6481, -3.0411, -3.078, -3.1668, -3.4437, -3.5552, -3.6866, -3.6935, -3.73, -3.7308, -3.7908, -3.7942, -3.8101, -3.9375, -3.9552, -3.8746, -4.008, -4.0641, -4.1119, -4.1806, -4.4952, -4.5241, -4.5344, -4.6023, -4.614, -4.6428, -4.6603, -4.6617, -3.6696], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5371, 1.537, 1.537, 1.537, 1.537, 1.5344, 1.5343, 1.534, 1.5339, 1.5339, 1.5332, 1.5331, 1.5331, 1.5329, 1.5327, 1.5326, 1.5324, 1.5324, 1.5324, 1.5321, 1.5319, 1.5318, 1.5311, 1.5304, 1.5304, 1.5302, 1.53, 1.5297, 1.5294, 1.5294, 1.6766, 1.6766, 1.6765, 1.6765, 1.6762, 1.6762, 1.6759, 1.6758, 1.6758, 1.6758, 1.6756, 1.6754, 1.6753, 1.6749, 1.6748, 1.6747, 1.6747, 1.6746, 1.6745, 1.6742, 1.674, 1.674, 1.6739, 1.6738, 1.6737, 1.6737, 1.6737, 1.6735, 1.6733, 1.6731, 1.6085, 1.5217, 1.7113, 1.7108, 1.7107, 1.7102, 1.7101, 1.7099, 1.7096, 1.7096, 1.7093, 1.7093, 1.7089, 1.7088, 1.7086, 1.7086, 1.7085, 1.7084, 1.708, 1.7079, 1.7078, 1.7075, 1.7074, 1.7074, 1.7074, 1.7074, 1.7073, 1.7071, 1.7071, 1.7069, 1.7069, 1.7069, 1.8512, 1.8505, 1.8497, 1.8495, 1.8494, 1.8492, 1.849, 1.8486, 1.8483, 1.8482, 1.8481, 1.848, 1.8478, 1.8478, 1.8477, 1.8476, 1.8474, 1.8474, 1.8472, 1.847, 1.847, 1.8466, 1.8466, 1.8465, 1.8464, 1.8461, 1.846, 1.8459, 1.8458, 1.8458, 1.8643, 1.8641, 1.8637, 1.8633, 1.8633, 1.8631, 1.8631, 1.8631, 1.8629, 1.8629, 1.8628, 1.8627, 1.8627, 1.8625, 1.8625, 1.8622, 1.8621, 1.8618, 1.8617, 1.8616, 1.8615, 1.8611, 1.8611, 1.8611, 1.861, 1.8609, 1.8606, 1.8605, 1.8604, 1.8602, 2.2448, 2.2446, 2.2444, 2.2438, 2.2437, 2.2436, 2.243, 2.2426, 2.2422, 2.2422, 2.2421, 2.242, 2.2419, 2.2419, 2.2418, 2.2413, 2.2412, 2.2412, 2.241, 2.2407, 2.2405, 2.2401, 2.2382, 2.238, 2.2379, 2.2374, 2.2373, 2.2369, 2.2369, 2.2369, 2.1891]}, \"token.table\": {\"Topic\": [4, 3, 6, 4, 4, 2, 2, 1, 5, 4, 1, 1, 5, 5, 5, 1, 1, 3, 2, 4, 1, 6, 1, 5, 5, 1, 4, 3, 5, 3, 3, 3, 4, 5, 1, 3, 2, 6, 2, 6, 6, 6, 1, 3, 5, 4, 6, 1, 4, 1, 4, 4, 2, 4, 2, 5, 3, 5, 2, 4, 2, 3, 6, 3, 6, 5, 5, 1, 2, 3, 2, 6, 4, 2, 2, 5, 2, 1, 4, 6, 6, 3, 3, 6, 5, 1, 4, 4, 4, 6, 1, 2, 3, 5, 6, 3, 4, 2, 4, 6, 6, 4, 5, 3, 5, 6, 5, 3, 4, 5, 2, 1, 2, 6, 2, 4, 2, 3, 4, 3, 5, 4, 2, 5, 5, 3, 2, 3, 1, 4, 3, 5, 6, 6, 6, 1, 6, 1, 2, 2, 1, 2, 2, 4, 1, 5, 1, 1, 3, 3, 6, 3, 5, 2, 6, 4, 3, 1, 5, 6, 2, 4, 2, 3, 5, 2, 6, 6, 3, 2, 1, 6, 2, 5, 1, 1, 6, 6, 4, 3, 4, 2, 5, 1, 5, 1, 6, 3, 3], \"Freq\": [0.9961779288238899, 0.9958969539546791, 0.9967596583704214, 0.9968106587270466, 0.9979400130319851, 0.9951381259878161, 0.9980378158564427, 0.9906972628901478, 0.9979459939526268, 0.9975736800916284, 0.9941671671669174, 0.9995063341242726, 0.9944431346409214, 0.9964489478451838, 0.9971872472099379, 0.9997637189893797, 0.9961358781453696, 0.9977637265159316, 0.9989824867418499, 0.9967011317691721, 0.9971300913705667, 0.9995282010256133, 0.9957952879234561, 0.9959493694646109, 0.9928919023458076, 0.995427763222016, 0.9979276629696427, 0.9937761703354552, 0.9977664306852283, 0.9975607337879215, 0.9955393688160985, 0.9983994677352507, 0.9984095309703644, 0.9960089318220728, 0.9995238574211688, 0.9934297800858936, 0.9974971173243891, 0.9935141789404778, 0.9984235861982315, 0.9951227473786144, 0.9991634695000181, 0.9977679108367721, 0.9951345210916779, 0.9969356925100324, 0.9973473353968577, 0.9940051117304004, 0.9947551506894036, 0.9967832455211477, 0.9984171761320074, 0.9935166716552032, 0.9972009995880985, 0.997250220852154, 0.9982646926902035, 0.9995728173889366, 0.9980803794022515, 0.9989135799149347, 0.9937733019519964, 0.996347357825077, 0.9939697593043428, 0.9960021814272821, 0.9336044492898948, 0.06278626413353093, 0.002729837571023084, 0.9983593837811995, 0.9888372118137541, 0.9972837360247222, 0.999255585276937, 0.9949693760216292, 0.9984446919683018, 0.9964372595625972, 0.9982534425422102, 0.9975287575736874, 0.9969345547674652, 0.9977581003920464, 0.996950289211178, 0.9992220884470348, 0.993192930661301, 0.9964753429948073, 0.9951174318100562, 0.9970273459544088, 0.9953927239745392, 0.999499270325093, 0.9972290208465268, 0.9947345658194993, 0.9981187552079898, 0.9964993632332383, 0.996342349402926, 0.9974107620872898, 0.9977181130698499, 0.98706428092911, 0.9891636193774239, 0.03760734550136082, 0.013675398364131208, 0.003418849591032802, 0.9436024871250533, 0.9951166843491107, 0.9958774127553863, 0.9950003738985608, 0.9936256552315994, 0.99561146263638, 0.9961125679438052, 0.9964644893722413, 0.9978859292664787, 0.995357909637259, 0.997350599116685, 0.9935673055336628, 0.9968851016372727, 0.9984648425395217, 0.9964330763577585, 0.9966185980212138, 0.9985867197637597, 0.9997733337904084, 0.9988322778462705, 0.9989810699502061, 0.8551771455243734, 0.14366976044809474, 0.9941612006137279, 0.9963835533394289, 0.9950162567607934, 0.9979016026828111, 0.9977434820204281, 0.9996020225732705, 0.998584203846108, 0.9966573691195548, 0.9966641990818023, 0.9966563855913623, 0.9980965472023693, 0.9953713761245511, 0.9951459800629703, 0.9930721105957052, 0.9979705376790763, 0.9979232619953756, 0.9956851860912208, 0.9920586991504874, 0.9988084423108405, 0.9951960481345975, 0.9970895946454246, 0.998403575220809, 0.9959529129683822, 0.9979754224409889, 0.9965348002581034, 0.9991706281300264, 0.9968883700935878, 0.9933299137713085, 0.9958181412839716, 0.9969887164718155, 0.9996218075686057, 0.9891546404056701, 0.9993233581540153, 0.9978884909831434, 0.9938913792185285, 0.9973774241528174, 0.9963740712458857, 0.9975449501391219, 0.9972639708362636, 0.9976308069589346, 0.9973403046619186, 0.9916055885764602, 0.9972814619267635, 0.9962827357376299, 0.9963086364494439, 0.9922984359413551, 0.9965771061363714, 0.9987089964064693, 0.9989928074325414, 0.9969281204826844, 0.9964353336610735, 0.9990657056688734, 0.9983222691245233, 0.9945574903933446, 0.995127952134128, 0.9968655461660464, 0.9964604930002154, 0.9974886071560671, 0.9940180583209162, 0.992194941066166, 0.9978985846869219, 0.9956314797710686, 0.9977924132548098, 0.9981852721800336, 0.992461524810808, 0.9975492626191675, 0.9964562269645721, 0.994356028515051, 0.9971046946571919, 0.9959380242171615, 0.9960990673117567, 0.9973749193033562, 0.9975506471368807], \"Term\": [\"access\", \"according\", \"active\", \"administered\", \"administers\", \"adults\", \"age\", \"ages\", \"americans\", \"anti\", \"appointment\", \"appointments\", \"april\", \"astrazeneca\", \"australia\", \"available\", \"based\", \"biden\", \"black\", \"blood\", \"canada\", \"cases\", \"cdc\", \"center\", \"centre\", \"check\", \"children\", \"china\", \"city\", \"coming\", \"continue\", \"countries\", \"country\", \"county\", \"cvs\", \"daily\", \"data\", \"day\", \"days\", \"dead\", \"death\", \"deaths\", \"developed\", \"die\", \"died\", \"dies\", \"discharges\", \"disease\", \"doctor\", \"doesn\", \"don\", \"dont\", \"dose\", \"doses\", \"drive\", \"dying\", \"effects\", \"emergency\", \"experts\", \"fake\", \"farm\", \"farm\", \"farm\", \"fight\", \"flu\", \"food\", \"fully\", \"future\", \"getting\", \"global\", \"going\", \"got\", \"government\", \"govt\", \"group\", \"health\", \"here\", \"high\", \"hospitals\", \"hours\", \"immunity\", \"india\", \"indian\", \"infections\", \"jab\", \"johnson\", \"kenyan\", \"know\", \"lack\", \"lakh\", \"latest\", \"laws\", \"laws\", \"laws\", \"laws\", \"life\", \"like\", \"live\", \"long\", \"look\", \"march\", \"mask\", \"masks\", \"mass\", \"million\", \"ministry\", \"moderna\", \"modi\", \"months\", \"mrna\", \"nation\", \"near\", \"need\", \"new\", \"news\", \"news\", \"now\", \"outbreak\", \"oxygen\", \"pandemic\", \"passed\", \"people\", \"pfizer\", \"population\", \"positive\", \"possible\", \"present\", \"public\", \"rate\", \"reactions\", \"read\", \"received\", \"recoveries\", \"reported\", \"reports\", \"research\", \"right\", \"risk\", \"said\", \"saturday\", \"says\", \"second\", \"shot\", \"shots\", \"shows\", \"sick\", \"sign\", \"sites\", \"situation\", \"soon\", \"spike\", \"spread\", \"stand\", \"start\", \"state\", \"states\", \"stop\", \"study\", \"supply\", \"taking\", \"tested\", \"testing\", \"think\", \"time\", \"times\", \"today\", \"toll\", \"total\", \"tough\", \"trials\", \"trump\", \"union\", \"update\", \"use\", \"variants\", \"vax\", \"virus\", \"wait\", \"want\", \"way\", \"wear\", \"weeks\", \"work\", \"workers\", \"world\", \"wrong\", \"year\", \"you\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 3, 2, 6, 5]};\n\nfunction LDAvis_load_lib(url, callback){\n  var s = document.createElement('script');\n  s.src = url;\n  s.async = true;\n  s.onreadystatechange = s.onload = callback;\n  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n  document.getElementsByTagName(\"head\")[0].appendChild(s);\n}\n\nif(typeof(LDAvis) !== \"undefined\"){\n   // already loaded: just create the visualization\n   !function(LDAvis){\n       new LDAvis(\"#\" + \"ldavis_el19731397749451037602771054418\", ldavis_el19731397749451037602771054418_data);\n   }(LDAvis);\n}else if(typeof define === \"function\" && define.amd){\n   // require.js is available: use it to load d3/LDAvis\n   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n   require([\"d3\"], function(d3){\n      window.d3 = d3;\n      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n        new LDAvis(\"#\" + \"ldavis_el19731397749451037602771054418\", ldavis_el19731397749451037602771054418_data);\n      });\n    });\n}else{\n    // require.js not available: dynamically load d3 & LDAvis\n    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n                 new LDAvis(\"#\" + \"ldavis_el19731397749451037602771054418\", ldavis_el19731397749451037602771054418_data);\n            })\n         });\n}\n</script>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "single_plot = pyLDAvis.gensim_models.prepare(single_model, single_corpus, single_dict)\n",
    "single_plot\n"
   ]
  },
  {
   "source": [
    "We can also try building a Mallet LDA model using either parameters identified above or any other parameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "# Download MalletLDA with: wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = '/usr/lib/mallet-2.0.8/bin/mallet'\n",
    "mallet_lda = gensim.models.wrappers.LdaMallet(mallet_path=mallet_path, corpus=single_corpus, num_topics=8, alpha='auto', id2word=single_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, '0.145*\"people\" + 0.041*\"virus\" + 0.031*\"cdc\" + 0.031*\"risk\" + 0.027*\"variants\" + 0.026*\"don\" + 0.022*\"public\" + 0.021*\"spread\" + 0.020*\"trump\" + 0.020*\"sites\"'), (1, '0.094*\"india\" + 0.088*\"cases\" + 0.044*\"deaths\" + 0.041*\"health\" + 0.036*\"total\" + 0.035*\"world\" + 0.032*\"death\" + 0.028*\"state\" + 0.026*\"reports\" + 0.022*\"americans\"'), (2, '0.079*\"news\" + 0.038*\"immunity\" + 0.036*\"die\" + 0.034*\"fake\" + 0.033*\"usa\" + 0.033*\"wait\" + 0.030*\"company\" + 0.030*\"medicine\" + 0.029*\"anti\" + 0.027*\"warned\"'), (3, '0.080*\"india\" + 0.045*\"drive\" + 0.034*\"time\" + 0.034*\"hospital\" + 0.034*\"country\" + 0.027*\"appointment\" + 0.027*\"start\" + 0.025*\"adults\" + 0.025*\"people\" + 0.024*\"times\"'), (4, '0.043*\"pandemic\" + 0.038*\"canada\" + 0.036*\"modi\" + 0.035*\"government\" + 0.034*\"johnson\" + 0.027*\"days\" + 0.025*\"year\" + 0.022*\"oxygen\" + 0.021*\"fight\" + 0.020*\"global\"'), (5, '0.100*\"doses\" + 0.049*\"fully\" + 0.039*\"million\" + 0.037*\"shot\" + 0.036*\"day\" + 0.034*\"administered\" + 0.028*\"population\" + 0.028*\"rate\" + 0.023*\"april\" + 0.022*\"lakh\"'), (6, '0.149*\"appointments\" + 0.136*\"sign\" + 0.132*\"cvs\" + 0.068*\"dose\" + 0.063*\"pfizer\" + 0.052*\"health\" + 0.047*\"emergency\" + 0.045*\"moderna\" + 0.026*\"check\" + 0.020*\"follow\"'), (7, '0.056*\"today\" + 0.049*\"age\" + 0.031*\"group\" + 0.030*\"years\" + 0.028*\"russia\" + 0.027*\"received\" + 0.027*\"sputnik\" + 0.020*\"centre\" + 0.019*\"begins\" + 0.019*\"phase\"')]\n",
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(mallet_lda.show_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "coherence_model_malletlda = CoherenceModel(model=mallet_lda,texts=tweets_nn_lst, dictionary=single_dict, coherence='c_v')\n",
    "coherence_malletlda = coherence_model_malletlda.get_coherence()\n",
    "print(coherence_malletlda)"
   ]
  },
  {
   "source": [
    "Additional things to try? Create bigram and trigram lists as well? Additional models to try? If so, use Gensim.models.phrases and gensim.models.phraser?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Other resources used: https://www.geeksforgeeks.org/python-convert-a-string-representation-of-list-into-list/; https://stackoverflow.com/questions/66759852/no-module-named-pyldavis; http://mallet.cs.umass.edu/download.php; https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/; https://thinkinfi.com/guide-to-build-best-lda-model-using-gensim-python/; https://medium.com/swlh/topic-modeling-lda-mallet-implementation-in-python-part-2-602ffb38d396; https://www.linkedin.com/pulse/nlp-a-complete-guide-topic-modeling-latent-dirichlet-sahil-m/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}