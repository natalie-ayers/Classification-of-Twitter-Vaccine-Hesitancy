{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd0cda595cc091c472e9dda46637922ba357e006ec97741f8a0b4e3fc352369fe49",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# LDA for COVID-19 Tweet Topic Identification\n",
    "\n",
    "This notebook to identify the primary topics in COVID-19 vaccine tweets is based on a variety of guides written by others:\n",
    "https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/; \n",
    "https://thinkinfi.com/guide-to-build-best-lda-model-using-gensim-python/; https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "First, we load in the packages we'll need - we'll primarily be using Gensim and the Gensim wrapper for Mallet for our LDA. We'll also load in our pre-processed, labeled data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/pylab/config.py:70: DeprecationWarning: InlineBackend._figure_formats_changed is deprecated in traitlets 4.1: use @observe and @unobserve instead.\n  def _figure_formats_changed(self, name, old, new):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = os.listdir('data/labeled')\n",
    "tweets_dfs = []\n",
    "for tweet in tweets:\n",
    "    tw_file = 'data/labeled/' + tweet\n",
    "    df = pd.read_json(tw_file)\n",
    "    tweets_dfs.append(df) \n",
    "tweets_clean = pd.concat(tweets_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_json('data/labeled/2021-04-19_cln_labeled.json')\n",
    "df_test.shape"
   ]
  },
  {
   "source": [
    "Filter to include only tweets which are negative or neutral, in order to better identify topics related to vaccine hesitancy."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_negneut = tweets_clean[tweets_clean['score'] < 0]\n",
    "tweets_negneut.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(text_clean_tok_lst, n):\n",
    "    output = []\n",
    "    for i in range(len(text_clean_tok_lst) - n + 1):\n",
    "        #print(text_clean_tok_lst[i:i + n])\n",
    "        output.append(' '.join(text_clean_tok_lst[i:i + n]))\n",
    "    #print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/tmp/ipykernel_1065/2446406582.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  tweets_negneut['digrams'] = None\n/tmp/ipykernel_1065/2446406582.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  tweets_negneut['digrams'][i] = ngrams(ast.literal_eval(tweets_negneut['text_cln_tok'][i]), 2)\n/home/npodpx/miniconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3437: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "tweets_negneut['digrams'] = None\n",
    "for i in range(tweets_negneut.shape[0]):\n",
    "    #print(i)\n",
    "    #print(ast.literal_eval(tweets_negneut['text_cln_tok'][i]))\n",
    "    tweets_negneut['digrams'][i] = ngrams(ast.literal_eval(tweets_negneut['text_cln_tok'][i]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n    Size of combined df:\t(25266, 10)\n    First five rows:\n\n       index                created_at  \\\n0      1 2021-04-27 04:03:50+00:00   \n1      5 2021-04-27 04:04:00+00:00   \n2      6 2021-04-27 04:04:03+00:00   \n3      8 2021-04-27 04:04:06+00:00   \n4     11 2021-04-27 04:04:08+00:00   \n\n                                            text_cln  \\\n0  don t know liberals s given doses capita count...   \n1  feel freely large moms family covid seriously ...   \n2    europe news coronavirus eu sues astrazeneca ...   \n3  covid  vaccine covaxin covidshield astrazeneca...   \n4  lies vaccinated ppl transmitting fr bodies har...   \n\n                                        text_cln_tok  positive  neutral  \\\n0  ['don', 'know', 'liberals', 'given', 'doses', ...     0.000    0.722   \n1  ['feel', 'freely', 'large', 'moms', 'family', ...     0.282    0.397   \n2  ['europe', 'news', 'sues', 'astrazeneca', 'del...     0.084    0.785   \n3  ['covaxin', 'astrazeneca', 'sputnik', 'pfizer'...     0.151    0.647   \n4  ['lies', 'ppl', 'transmitting', 'bodies', 'har...     0.121    0.704   \n\n   negative  compound  score  \\\n0     0.278   -0.6124     -1   \n1     0.321   -0.2732     -1   \n2     0.131   -0.2100     -1   \n3     0.201   -0.1027     -1   \n4     0.176   -0.2732     -1   \n\n                                             digrams  \n0  [don know, know liberals, liberals given, give...  \n1  [feel freely, freely large, large moms, moms f...  \n2  [europe news, news sues, sues astrazeneca, ast...  \n3  [covaxin astrazeneca, astrazeneca sputnik, spu...  \n4  [lies ppl, ppl transmitting, transmitting bodi...  \n\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"\n",
    "    Size of combined df:\\t{}\n",
    "    First five rows:\n",
    "\n",
    "    {}\n",
    "\"\"\".format(\n",
    "    tweets_negneut.shape,\n",
    "    tweets_negneut.head()\n",
    ")\n",
    ")\n"
   ]
  },
  {
   "source": [
    "First (if desired), we can perform a grid search of possible parameters for both the Gensim and Mallet LDA models to identify the most promising. To do this, use the function choose_lda_models() in pipeline.py with the text_cln_tok column of the full tweets dataframe. In order to successfully run pipeline (for the Mallet LDA model), you'll need to download the Mallet LDA (download with: wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip), unzip it, and re-assign the variable MALLET_PATH in pipeline.py to be the file path where the ballet-2.0.8/bin/mallet files are located (eg, MALLET_PATH = '/usr/lib/mallet-2.0.8/bin/mallet'). You also need to insure all packages used in pipeline.py are installed. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Note on grid search: currently, the parameters to search through are hard-coded in pipeline.py. To search through different parameters, you'll need to adjust the parameter values in choose_lda_models. The initial step of creating a dictionary and corpus to use in the LDA models also takes parameters, which are currently hard-coded to not consider words which appear less than 50 times, words which appear in more than 80 % of the documents, and to filter for only the top 1000000 words. This can also be changed in pipeline.py when build_corpus_dict is called by choose_lda_models."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'pipeline' from '/mnt/c/Users/natra/Documents/Education/UChicago/MLforPP/ml-for-pp_vaccine-hesitancy/pipeline.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "import pipeline\n",
    "#import importlib\n",
    "#from src import pipeline\n",
    "#import src\n",
    "#reload(src.pipeline)\n",
    "import importlib\n",
    "importlib.reload(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "se days canada reports year time modi blood country \n",
      "1\t0.1\tpeople fake don die immunity mask usa virus medicine company wait produced listen dont therapeutics ennaid humanity masks fully cure \n",
      "2\t0.1\thealth people emergency world anti biden india school countries pandemic news global private patents doses fight trump patent moderna teachers \n",
      "\n",
      "<250> LL/token: -5.23769\n",
      "<260> LL/token: -5.23402\n",
      "<270> LL/token: -5.23743\n",
      "<280> LL/token: -5.23335\n",
      "<290> LL/token: -5.234\n",
      "\n",
      "0\t0.1\tindia cases people death health deaths risk total astrazeneca pfizer dose died days canada reports modi time year blood country \n",
      "1\t0.1\tpeople fake don die immunity mask virus usa medicine company wait produced listen fully therapeutics dont ennaid humanity masks cure \n",
      "2\t0.1\thealth emergency people world anti biden countries school india news pandemic global private patents trump doses moderna patent teachers fight \n",
      "\n",
      "<300> LL/token: -5.23479\n",
      "<310> LL/token: -5.23871\n",
      "<320> LL/token: -5.23671\n",
      "<330> LL/token: -5.23757\n",
      "<340> LL/token: -5.23528\n",
      "\n",
      "0\t0.1\tindia cases people death deaths health risk total died pfizer astrazeneca dose days canada reports year modi blood time adverse \n",
      "1\t0.1\tpeople fake don die mask immunity usa virus company medicine wait produced listen therapeutics ennaid humanity masks dont fully cure \n",
      "2\t0.1\thealth emergency people world anti india countries biden school pandemic news global private patents doses moderna patent teachers big fight \n",
      "\n",
      "<350> LL/token: -5.22958\n",
      "<360> LL/token: -5.23381\n",
      "<370> LL/token: -5.23705\n",
      "<380> LL/token: -5.23903\n",
      "<390> LL/token: -5.23806\n",
      "\n",
      "0\t0.1\tindia cases people death health deaths risk total pfizer astrazeneca died dose days canada reports year modi blood time adverse \n",
      "1\t0.1\tpeople fake don die mask immunity usa medicine virus company wait produced listen therapeutics ennaid dont humanity masks cure fully \n",
      "2\t0.1\thealth people emergency world anti india countries biden school pandemic news global private doses patents trump fight moderna patent teachers \n",
      "\n",
      "<400> LL/token: -5.23801\n",
      "<410> LL/token: -5.23634\n",
      "<420> LL/token: -5.23201\n",
      "<430> LL/token: -5.23601\n",
      "<440> LL/token: -5.23573\n",
      "\n",
      "0\t0.1\tindia cases people death deaths health risk total pfizer astrazeneca died dose days canada reports year modi time blood doses \n",
      "1\t0.1\tpeople fake don die immunity mask usa virus medicine company wait produced listen therapeutics ennaid humanity masks dont stop fully \n",
      "2\t0.1\thealth people emergency world india anti countries biden school pandemic news global private patents doses trump patent fight teachers big \n",
      "\n",
      "<450> LL/token: -5.23819\n",
      "<460> LL/token: -5.23653\n",
      "<470> LL/token: -5.23778\n",
      "<480> LL/token: -5.23122\n",
      "<490> LL/token: -5.23092\n",
      "\n",
      "0\t0.1\tindia cases people death deaths health risk total pfizer dose died astrazeneca days canada reports year modi time blood virus \n",
      "1\t0.1\tpeople fake don die immunity mask usa virus medicine company wait produced listen therapeutics ennaid humanity masks fully dont cure \n",
      "2\t0.1\thealth emergency people world anti countries india biden school pandemic news global private patents doses moderna trump patent teachers fight \n",
      "\n",
      "<500> LL/token: -5.23528\n",
      "<510> LL/token: -5.2339\n",
      "<520> LL/token: -5.23734\n",
      "<530> LL/token: -5.23552\n",
      "<540> LL/token: -5.23303\n",
      "\n",
      "0\t0.1\tindia cases people death health deaths total risk dose pfizer astrazeneca died days canada year reports time modi blood country \n",
      "1\t0.1\tpeople fake don mask immunity die usa virus medicine company wait produced listen therapeutics fully ennaid humanity masks stop cure \n",
      "2\t0.1\thealth people emergency world anti india countries biden school pandemic news global private patents doses fight trump patent moderna teachers \n",
      "\n",
      "<550> LL/token: -5.23565\n",
      "<560> LL/token: -5.23303\n",
      "<570> LL/token: -5.2401\n",
      "<580> LL/token: -5.23432\n",
      "<590> LL/token: -5.23728\n",
      "\n",
      "0\t0.1\tindia cases people death deaths health total risk astrazeneca pfizer died dose days reports canada year modi time blood country \n",
      "1\t0.1\tpeople fake don die mask immunity usa virus medicine company wait produced listen therapeutics dont fully ennaid humanity masks cure \n",
      "2\t0.1\thealth people emergency world anti biden countries india school pandemic news global private patents doses moderna trump patent fight teachers \n",
      "\n",
      "<600> LL/token: -5.23402\n",
      "<610> LL/token: -5.23476\n",
      "<620> LL/token: -5.23964\n",
      "<630> LL/token: -5.23694\n",
      "<640> LL/token: -5.236\n",
      "\n",
      "0\t0.1\tindia cases people death deaths health risk total astrazeneca died pfizer days canada reports year modi blood dose time country \n",
      "1\t0.1\tpeople fake don die mask immunity usa virus medicine company wait produced listen therapeutics fully ennaid masks dont humanity cure \n",
      "2\t0.1\thealth emergency world people india biden countries school anti news pandemic global doses private patents dose moderna patent teachers fight \n",
      "\n",
      "<650> LL/token: -5.2349\n",
      "<660> LL/token: -5.23\n",
      "<670> LL/token: -5.23093\n",
      "<680> LL/token: -5.22852\n",
      "<690> LL/token: -5.23137\n",
      "\n",
      "0\t0.1\tindia cases people death deaths health risk total died astrazeneca pfizer days reports canada year modi blood dose time doses \n",
      "1\t0.1\tpeople fake don immunity mask die usa virus medicine company wait produced cdc listen therapeutics ennaid anti masks cure humanity \n",
      "2\t0.1\thealth emergency world india people countries biden school pandemic news global private patents dose doses moderna fight patent teachers anti \n",
      "\n",
      "<700> LL/token: -5.2362\n",
      "<710> LL/token: -5.23661\n",
      "<720> LL/token: -5.23037\n",
      "<730> LL/token: -5.23135\n",
      "<740> LL/token: -5.23229\n",
      "\n",
      "0\t0.1\tindia cases people death deaths risk health total pfizer died days astrazeneca reports time year canada modi virus blood dose \n",
      "1\t0.1\tpeople fake don mask immunity die anti usa medicine company virus wait produced listen cdc therapeutics ennaid dont masks cure \n",
      "2\t0.1\thealth emergency world india countries people pandemic biden school doses global news private dose patents fight moderna patent teachers big \n",
      "\n",
      "<750> LL/token: -5.23098\n",
      "<760> LL/token: -5.22499\n",
      "<770> LL/token: -5.22557\n",
      "<780> LL/token: -5.22966\n",
      "<790> LL/token: -5.22885\n",
      "\n",
      "0\t0.1\tindia cases people death deaths risk health total died days pfizer astrazeneca reports canada year modi blood virus time dose \n",
      "1\t0.1\tpeople fake don anti mask immunity die usa medicine company virus wait produced listen therapeutics cdc ennaid masks humanity cure \n",
      "2\t0.1\thealth india emergency world countries pandemic school biden people doses global private dose patents fight news moderna patent teachers big \n",
      "\n",
      "<800> LL/token: -5.22668\n",
      "<810> LL/token: -5.22298\n",
      "<820> LL/token: -5.2242\n",
      "<830> LL/token: -5.22605\n",
      "<840> LL/token: -5.22794\n",
      "\n",
      "0\t0.1\tpeople cases india death deaths risk health total died days pfizer astrazeneca reports canada year virus dose modi time blood \n",
      "1\t0.1\tpeople fake don mask anti die immunity usa medicine company wait produced virus listen therapeutics cdc ennaid masks cure humanity \n",
      "2\t0.1\thealth india emergency world countries people biden pandemic school doses global private patents dose news fight moderna patent teachers big \n",
      "\n",
      "<850> LL/token: -5.22797\n",
      "<860> LL/token: -5.2288\n",
      "<870> LL/token: -5.22824\n",
      "<880> LL/token: -5.22617\n",
      "<890> LL/token: -5.22422\n",
      "\n",
      "0\t0.1\tcases people india death risk deaths health total died pfizer days astrazeneca virus reports canada year dose modi time blood \n",
      "1\t0.1\tpeople fake don mask anti die immunity usa medicine company wait virus produced listen therapeutics cdc ennaid masks humanity cure \n",
      "2\t0.1\thealth india emergency world countries people pandemic biden school doses global private patents news moderna dose fight patent teachers big \n",
      "\n",
      "<900> LL/token: -5.22676\n",
      "<910> LL/token: -5.22604\n",
      "<920> LL/token: -5.22819\n",
      "<930> LL/token: -5.22301\n",
      "<940> LL/token: -5.22548\n",
      "\n",
      "0\t0.1\tcases people india death risk deaths health total died pfizer days astrazeneca virus reports year canada dose modi time blood \n",
      "1\t0.1\tpeople fake don anti mask immunity die usa medicine company wait produced listen therapeutics ennaid cdc masks virus dont cure \n",
      "2\t0.1\thealth india emergency world countries pandemic biden school people doses global private patents news fight dose moderna patent teachers big \n",
      "\n",
      "<950> LL/token: -5.23022\n",
      "<960> LL/token: -5.22519\n",
      "<970> LL/token: -5.22622\n",
      "<980> LL/token: -5.2283\n",
      "<990> LL/token: -5.22679\n",
      "\n",
      "0\t0.1\tcases people india death risk deaths health total pfizer died astrazeneca days virus canada reports year time dose modi blood \n",
      "1\t0.1\tpeople fake don mask anti die immunity usa medicine company wait produced cdc listen therapeutics ennaid masks cure humanity dont \n",
      "2\t0.1\thealth india emergency world countries pandemic people biden school doses global private news patents fight moderna dose patent teachers big \n",
      "\n",
      "<1000> LL/token: -5.2202\n",
      "\n",
      "Total time: 32 seconds\n",
      "Time Elapsed: 0:00:34.929390\n",
      "Training model: MalletLDA | {'num_topics': 3, 'alpha': 0.6, 'random_seed': 100}\n",
      "Mallet LDA: 3 topics, 2 topic bits, 11 topic mask\n",
      "Data loaded.\n",
      "max tokens: 20\n",
      "total tokens: 97605\n",
      "<10> LL/token: -5.73359\n",
      "<20> LL/token: -5.31517\n",
      "<30> LL/token: -5.21953\n",
      "<40> LL/token: -5.20126\n",
      "\n",
      "0\t0.2\tindia cases health death people total deaths doses countries world pandemic country government canada global astrazeneca crisis reports news fight \n",
      "1\t0.2\tpeople risk virus emergency health dose pfizer fully mask shot cdc don stop moderna died effects dont spread disease variants \n",
      "2\t0.2\tfake school usa biden medicine die company anti private immunity patents warned produced people wait listen therapeutics patent ennaid big \n",
      "\n",
      "<50> LL/token: -5.20049\n",
      "<60> LL/token: -5.19356\n",
      "<70> LL/token: -5.18742\n",
      "<80> LL/token: -5.18414\n",
      "<90> LL/token: -5.18737\n",
      "\n",
      "0\t0.2\tindia cases health death people total doses world pandemic deaths countries country global government canada crisis reports time fight modi \n",
      "1\t0.2\tpeople risk virus emergency pfizer health dose fully shot cdc mask died don stop moderna effects dont disease spread americans \n",
      "2\t0.2\tfake usa school biden medicine company die immunity private anti patents people warned produced wait listen therapeutics patent ennaid big \n",
      "\n",
      "<100> LL/token: -5.19204\n",
      "<110> LL/token: -5.18545\n",
      "<120> LL/token: -5.18191\n",
      "<130> LL/token: -5.18334\n",
      "<140> LL/token: -5.18337\n",
      "\n",
      "0\t0.2\tindia cases health death people total doses world pandemic deaths countries country government canada global crisis reports time fight news \n",
      "1\t0.2\tpeople risk virus emergency pfizer fully health dose shot cdc mask died don stop moderna effects disease dont spread death \n",
      "2\t0.2\tfake usa school biden medicine die company immunity private patents warned anti produced wait people listen big therapeutics patent ennaid \n",
      "\n",
      "<150> LL/token: -5.18424\n",
      "<160> LL/token: -5.18012\n",
      "<170> LL/token: -5.1834\n",
      "<180> LL/token: -5.18391\n",
      "<190> LL/token: -5.18416\n",
      "\n",
      "0\t0.2\tindia cases health people death doses total world pandemic deaths countries country government global canada crisis reports time fight modi \n",
      "1\t0.2\tpeople risk virus emergency pfizer dose health fully shot mask cdc died stop don moderna effects disease dont death spread \n",
      "2\t0.2\tfake usa school biden medicine company immunity die private warned anti patents produced wait listen big therapeutics patent ennaid people \n",
      "\n",
      "<200> LL/token: -5.1828\n",
      "<210> LL/token: -5.18146\n",
      "<220> LL/token: -5.18501\n",
      "<230> LL/token: -5.18133\n",
      "<240> LL/token: -5.18213\n",
      "\n",
      "0\t0.2\tindia cases health death people doses total world deaths pandemic countries country global government canada reports crisis time news fight \n",
      "1\t0.2\tpeople risk virus emergency pfizer health fully shot dose cdc mask died don stop moderna effects dont disease spread americans \n",
      "2\t0.2\tfake usa school medicine biden die company immunity private warned produced patents anti people wait listen big therapeutics patent ennaid \n",
      "\n",
      "<250> LL/token: -5.18417\n",
      "<260> LL/token: -5.18073\n",
      "<270> LL/token: -5.18451\n",
      "<280> LL/token: -5.17943\n",
      "<290> LL/token: -5.18138\n",
      "\n",
      "0\t0.2\tindia cases health death people doses total world deaths countries pandemic country government canada global crisis reports time fight modi \n",
      "1\t0.2\tpeople risk virus emergency pfizer fully health dose shot cdc mask don died stop moderna effects dont disease spread death \n",
      "2\t0.2\tfake usa school biden medicine die company private immunity anti warned produced patents listen wait big therapeutics people patent ennaid \n",
      "\n",
      "<300> LL/token: -5.18533\n",
      "<310> LL/token: -5.18139\n",
      "<320> LL/token: -5.18251\n",
      "<330> LL/token: -5.18538\n",
      "<340> LL/token: -5.1868\n",
      "\n",
      "0\t0.2\tindia cases health death people doses total world pandemic countries deaths country global government canada crisis reports time fight modi \n",
      "1\t0.2\tpeople risk virus emergency health fully dose pfizer shot cdc mask died don stop moderna effects disease spread death dont \n",
      "2\t0.2\tfake usa school biden medicine company die immunity private anti people warned produced wait listen patents therapeutics big patent ennaid \n",
      "\n",
      "<350> LL/token: -5.18345\n",
      "<360> LL/token: -5.18418\n",
      "<370> LL/token: -5.18756\n",
      "<380> LL/token: -5.18038\n",
      "<390> LL/token: -5.18297\n",
      "\n",
      "0\t0.2\tindia cases health death people doses total world pandemic deaths countries country global canada government crisis reports time fight modi \n",
      "1\t0.2\tpeople risk virus emergency pfizer dose fully health shot cdc mask died stop moderna don effects disease dont spread variants \n",
      "2\t0.2\tfake usa school biden medicine company anti die immunity private warned people produced wait listen therapeutics big patents patent ennaid \n",
      "\n",
      "<400> LL/token: -5.18501\n",
      "<410> LL/token: -5.18316\n",
      "<420> LL/token: -5.18132\n",
      "<430> LL/token: -5.1848\n",
      "<440> LL/token: -5.17752\n",
      "\n",
      "0\t0.2\tindia cases health death people doses total world pandemic deaths countries country global government canada crisis time reports news fight \n",
      "1\t0.2\tpeople risk virus emergency pfizer health fully dose shot cdc mask died don moderna stop effects disease dont spread death \n",
      "2\t0.2\tfake usa school biden medicine die company private immunity anti warned people produced wait listen therapeutics patent ennaid big patents \n",
      "\n",
      "<450> LL/token: -5.18208\n",
      "<460> LL/token: -5.18184\n",
      "<470> LL/token: -5.18754\n",
      "<480> LL/token: -5.18507\n",
      "<490> LL/token: -5.18054\n",
      "\n",
      "0\t0.2\tindia cases health death people doses total world pandemic deaths countries country global canada government crisis time reports fight news \n",
      "1\t0.2\tpeople risk virus emergency pfizer health fully dose shot cdc mask died don stop moderna effects disease dont spread death \n",
      "2\t0.2\tfake usa school biden medicine die company immunity private anti warned wait produced people listen patents therapeutics big patent ennaid \n",
      "\n",
      "<500> LL/token: -5.1814\n",
      "<510> LL/token: -5.18105\n",
      "<520> LL/token: -5.1861\n",
      "<530> LL/token: -5.18168\n",
      "<540> LL/token: -5.18308\n",
      "\n",
      "0\t0.2\tindia cases health people death doses total pandemic world countries deaths country global canada government crisis time reports fight modi \n",
      "1\t0.2\tpeople risk virus emergency pfizer health fully dose shot cdc mask died don stop moderna effects death disease dont spread \n",
      "2\t0.2\tfake usa school biden medicine die company people anti private immunity warned wait produced listen therapeutics patent ennaid teachers humanity \n",
      "\n",
      "<550> LL/token: -5.1808\n",
      "<560> LL/token: -5.18105\n",
      "<570> LL/token: -5.17974\n",
      "<580> LL/token: -5.18123\n",
      "<590> LL/token: -5.18222\n",
      "\n",
      "0\t0.2\tindia cases health people death doses total world pandemic deaths countries global country canada government crisis time reports fight modi \n",
      "1\t0.2\tpeople risk virus emergency pfizer fully health dose shot cdc died mask don moderna stop effects dont death disease spread \n",
      "2\t0.2\tfake usa school medicine biden immunity die company anti private warned produced people wait listen therapeutics patents patent big ennaid \n",
      "\n",
      "<600> LL/token: -5.18339\n",
      "<610> LL/token: -5.17919\n",
      "<620> LL/token: -5.18223\n",
      "<630> LL/token: -5.18147\n",
      "<640> LL/token: -5.18378\n",
      "\n",
      "0\t0.2\tindia cases health people death doses total world pandemic countries deaths global country government canada crisis reports time fight modi \n",
      "1\t0.2\tpeople risk virus emergency pfizer health dose fully shot cdc mask died stop don moderna effects disease dont spread variants \n",
      "2\t0.2\tfake usa school biden medicine die company immunity private warned produced wait anti patents listen people therapeutics patent ennaid big \n",
      "\n",
      "<650> LL/token: -5.18312\n",
      "<660> LL/token: -5.18293\n",
      "<670> LL/token: -5.18169\n",
      "<680> LL/token: -5.18114\n",
      "<690> LL/token: -5.18369\n",
      "\n",
      "0\t0.2\tindia cases health death people doses total world pandemic deaths countries global country government canada crisis reports time fight modi \n",
      "1\t0.2\tpeople risk virus pfizer emergency dose health fully mask cdc shot died don stop moderna effects dont disease death spread \n",
      "2\t0.2\tfake usa school biden medicine die company immunity private anti warned produced people wait listen therapeutics patents big patent ennaid \n",
      "\n",
      "<700> LL/token: -5.1822\n",
      "<710> LL/token: -5.18114\n",
      "<720> LL/token: -5.18298\n",
      "<730> LL/token: -5.18788\n",
      "<740> LL/token: -5.18673\n",
      "\n",
      "0\t0.2\tindia cases health death people doses total world pandemic countries deaths country global canada crisis time government reports news fight \n",
      "1\t0.2\tpeople risk virus emergency pfizer dose fully health shot cdc mask died stop moderna effects don dont disease spread death \n",
      "2\t0.2\tfake usa school medicine biden die company immunity private anti people warned produced wait listen therapeutics patent patents big ennaid \n",
      "\n",
      "<750> LL/token: -5.18213\n",
      "<760> LL/token: -5.18417\n",
      "<770> LL/token: -5.17971\n",
      "<780> LL/token: -5.18106\n",
      "<790> LL/token: -5.18114\n",
      "\n",
      "0\t0.2\tindia cases health death people doses total world pandemic countries deaths country global government canada crisis reports fight time modi \n",
      "1\t0.2\tpeople risk virus emergency pfizer health dose fully shot cdc mask died don stop moderna effects disease spread dont americans \n",
      "2\t0.2\tfake usa school biden medicine company die immunity private anti warned produced wait listen therapeutics patent ennaid people teachers humanity \n",
      "\n",
      "<800> LL/token: -5.18171\n",
      "<810> LL/token: -5.18114\n",
      "<820> LL/token: -5.18003\n",
      "<830> LL/token: -5.17941\n",
      "<840> LL/token: -5.17781\n",
      "\n",
      "0\t0.2\tindia cases health people death total doses world deaths countries pandemic global country government canada crisis reports time fight modi \n",
      "1\t0.2\tpeople risk virus emergency pfizer fully health dose shot cdc mask died stop don moderna effects disease dont death spread \n",
      "2\t0.2\tfake usa school biden medicine die company immunity private warned produced wait anti listen therapeutics big patents patent ennaid people \n",
      "\n",
      "<850> LL/token: -5.18462\n",
      "<860> LL/token: -5.18448\n",
      "<870> LL/token: -5.18281\n",
      "<880> LL/token: -5.18115\n",
      "<890> LL/token: -5.18136\n",
      "\n",
      "0\t0.2\tindia cases health people death total doses pandemic world deaths countries country global government canada reports crisis fight time news \n",
      "1\t0.2\tpeople risk virus emergency pfizer dose fully health shot mask cdc died don stop moderna effects death dont disease spread \n",
      "2\t0.2\tfake usa school biden medicine company die immunity private anti warned wait produced people listen therapeutics patents big patent ennaid \n",
      "\n",
      "<900> LL/token: -5.17909\n",
      "<910> LL/token: -5.18042\n",
      "<920> LL/token: -5.18131\n",
      "<930> LL/token: -5.17793\n",
      "<940> LL/token: -5.17817\n",
      "\n",
      "0\t0.2\tindia cases health death people total doses world pandemic countries deaths global country canada government crisis reports time fight news \n",
      "1\t0.2\tpeople risk virus emergency pfizer dose fully health cdc mask shot died stop don moderna effects disease spread dont death \n",
      "2\t0.2\tfake usa school biden medicine die company anti immunity private warned people produced listen big wait therapeutics patent ennaid patents \n",
      "\n",
      "<950> LL/token: -5.18499\n",
      "<960> LL/token: -5.17898\n",
      "<970> LL/token: -5.17718\n",
      "<980> LL/token: -5.17778\n",
      "<990> LL/token: -5.17996\n",
      "\n",
      "0\t0.2\tindia cases health people death total doses world pandemic countries deaths country global government canada crisis time reports news fight \n",
      "1\t0.2\tpeople risk virus pfizer emergency fully health dose shot cdc died mask stop don moderna effects death disease dont spread \n",
      "2\t0.2\tfake usa school biden medicine die company immunity private anti warned produced people wait listen big therapeutics patents patent ennaid \n",
      "\n",
      "<1000> LL/token: -5.1772\n",
      "\n",
      "Total time: 32 seconds\n",
      "Time Elapsed: 0:00:35.149219\n",
      "Training model: MalletLDA | {'num_topics': 3, 'alpha': 'symmetric', 'random_seed': 100}\n",
      "\n",
      "For input string: \"symmetric\"\n"
     ]
    }
   ],
   "source": [
    "results = pipeline.choose_lda_models(tweets_negneut['text_cln_tok'])\n",
    "#results = pipeline.choose_lda_models(test_tweets['text_cln_tok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     LDA Model                                             Params  \\\n",
       "183  GensimLDA  {'chunksize': 2000, 'num_topics': 10, 'alpha':...   \n",
       "201  GensimLDA  {'chunksize': 2000, 'num_topics': 10, 'alpha':...   \n",
       "75   GensimLDA  {'chunksize': 1000, 'num_topics': 10, 'alpha':...   \n",
       "76   GensimLDA  {'chunksize': 1000, 'num_topics': 10, 'alpha':...   \n",
       "182  GensimLDA  {'chunksize': 2000, 'num_topics': 10, 'alpha':...   \n",
       "..         ...                                                ...   \n",
       "11   GensimLDA  {'chunksize': 1000, 'num_topics': 3, 'alpha': ...   \n",
       "7    GensimLDA  {'chunksize': 1000, 'num_topics': 3, 'alpha': ...   \n",
       "43   GensimLDA  {'chunksize': 1000, 'num_topics': 5, 'alpha': ...   \n",
       "6    GensimLDA  {'chunksize': 1000, 'num_topics': 3, 'alpha': ...   \n",
       "47   GensimLDA  {'chunksize': 1000, 'num_topics': 5, 'alpha': ...   \n",
       "\n",
       "              Time Elapsed  Coherence Perplexity  \\\n",
       "183 0 days 00:00:28.049147   0.410590  -5.102324   \n",
       "201 0 days 00:00:28.520705   0.410590  -5.102324   \n",
       "75  0 days 00:00:22.666379   0.407200  -5.080135   \n",
       "76  0 days 00:00:21.138000   0.405391  -5.092708   \n",
       "182 0 days 00:00:27.381447   0.404054  -5.091282   \n",
       "..                     ...        ...        ...   \n",
       "11  0 days 00:00:28.099501   0.222089    -5.1583   \n",
       "7   0 days 00:00:28.290769   0.222089  -5.157852   \n",
       "43  0 days 00:00:22.464876   0.221264  -5.110934   \n",
       "6   0 days 00:00:28.442079   0.220203  -5.212789   \n",
       "47  0 days 00:00:20.309174   0.217296  -5.108943   \n",
       "\n",
       "                                                Topics  \n",
       "183  [(0, 0.167*\"cases\" + 0.165*\"new\" + 0.164*\"deat...  \n",
       "201  [(0, 0.167*\"cases\" + 0.165*\"new\" + 0.164*\"deat...  \n",
       "75   [(0, 0.162*\"cases\" + 0.148*\"death\" + 0.142*\"ne...  \n",
       "76   [(0, 0.161*\"cases\" + 0.147*\"death\" + 0.141*\"ne...  \n",
       "182  [(0, 0.171*\"cases\" + 0.168*\"new\" + 0.168*\"deat...  \n",
       "..                                                 ...  \n",
       "11   [(0, 0.076*\"cases\" + 0.070*\"death\" + 0.049*\"fa...  \n",
       "7    [(0, 0.076*\"cases\" + 0.070*\"death\" + 0.049*\"fa...  \n",
       "43   [(0, 0.091*\"cases\" + 0.083*\"death\" + 0.080*\"ne...  \n",
       "6    [(0, 0.078*\"cases\" + 0.071*\"death\" + 0.050*\"fa...  \n",
       "47   [(0, 0.091*\"cases\" + 0.083*\"death\" + 0.080*\"ne...  \n",
       "\n",
       "[243 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LDA Model</th>\n      <th>Params</th>\n      <th>Time Elapsed</th>\n      <th>Coherence</th>\n      <th>Perplexity</th>\n      <th>Topics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>183</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 2000, 'num_topics': 10, 'alpha':...</td>\n      <td>0 days 00:00:28.049147</td>\n      <td>0.410590</td>\n      <td>-5.102324</td>\n      <td>[(0, 0.167*\"cases\" + 0.165*\"new\" + 0.164*\"deat...</td>\n    </tr>\n    <tr>\n      <th>201</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 2000, 'num_topics': 10, 'alpha':...</td>\n      <td>0 days 00:00:28.520705</td>\n      <td>0.410590</td>\n      <td>-5.102324</td>\n      <td>[(0, 0.167*\"cases\" + 0.165*\"new\" + 0.164*\"deat...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 10, 'alpha':...</td>\n      <td>0 days 00:00:22.666379</td>\n      <td>0.407200</td>\n      <td>-5.080135</td>\n      <td>[(0, 0.162*\"cases\" + 0.148*\"death\" + 0.142*\"ne...</td>\n    </tr>\n    <tr>\n      <th>76</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 10, 'alpha':...</td>\n      <td>0 days 00:00:21.138000</td>\n      <td>0.405391</td>\n      <td>-5.092708</td>\n      <td>[(0, 0.161*\"cases\" + 0.147*\"death\" + 0.141*\"ne...</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 2000, 'num_topics': 10, 'alpha':...</td>\n      <td>0 days 00:00:27.381447</td>\n      <td>0.404054</td>\n      <td>-5.091282</td>\n      <td>[(0, 0.171*\"cases\" + 0.168*\"new\" + 0.168*\"deat...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 3, 'alpha': ...</td>\n      <td>0 days 00:00:28.099501</td>\n      <td>0.222089</td>\n      <td>-5.1583</td>\n      <td>[(0, 0.076*\"cases\" + 0.070*\"death\" + 0.049*\"fa...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 3, 'alpha': ...</td>\n      <td>0 days 00:00:28.290769</td>\n      <td>0.222089</td>\n      <td>-5.157852</td>\n      <td>[(0, 0.076*\"cases\" + 0.070*\"death\" + 0.049*\"fa...</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 5, 'alpha': ...</td>\n      <td>0 days 00:00:22.464876</td>\n      <td>0.221264</td>\n      <td>-5.110934</td>\n      <td>[(0, 0.091*\"cases\" + 0.083*\"death\" + 0.080*\"ne...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 3, 'alpha': ...</td>\n      <td>0 days 00:00:28.442079</td>\n      <td>0.220203</td>\n      <td>-5.212789</td>\n      <td>[(0, 0.078*\"cases\" + 0.071*\"death\" + 0.050*\"fa...</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 5, 'alpha': ...</td>\n      <td>0 days 00:00:20.309174</td>\n      <td>0.217296</td>\n      <td>-5.108943</td>\n      <td>[(0, 0.091*\"cases\" + 0.083*\"death\" + 0.080*\"ne...</td>\n    </tr>\n  </tbody>\n</table>\n<p>243 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "results.sort_values('Coherence',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('lda_models_gs_3day.csv')"
   ]
  },
  {
   "source": [
    "With Digrams, we can see if the results are better:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10> LL/token: -7.8225\n",
      "<20> LL/token: -7.34142\n",
      "<30> LL/token: -7.30334\n",
      "<40> LL/token: -7.29061\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid immunity fake providing ego prevailed racism warned usa listen medicine die wait humanity produced cure love reading \n",
      "2\t0.1\ttherapeutics ennaid company cure produced humanity wait die medicine listen usa warned racism prevailed providing ego immunity fake reading love \n",
      "\n",
      "<50> LL/token: -7.29369\n",
      "<60> LL/token: -7.28671\n",
      "<70> LL/token: -7.2936\n",
      "<80> LL/token: -7.30352\n",
      "<90> LL/token: -7.30015\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid racism humanity warned produced wait prevailed die fake ego cure medicine usa listen immunity providing love reading \n",
      "2\t0.1\ttherapeutics ennaid company immunity providing usa listen medicine cure fake ego die prevailed wait produced warned humanity racism reading love \n",
      "\n",
      "<100> LL/token: -7.30286\n",
      "<110> LL/token: -7.29445\n",
      "<120> LL/token: -7.29562\n",
      "<130> LL/token: -7.27269\n",
      "<140> LL/token: -7.28117\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid immunity racism fake prevailed ego wait medicine listen providing usa produced warned cure die humanity reading love \n",
      "2\t0.1\ttherapeutics ennaid company humanity die warned cure produced usa listen providing wait medicine ego prevailed fake racism immunity love reading \n",
      "\n",
      "<150> LL/token: -7.29708\n",
      "<160> LL/token: -7.28489\n",
      "<170> LL/token: -7.28298\n",
      "<180> LL/token: -7.28786\n",
      "<190> LL/token: -7.2837\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid prevailed fake medicine immunity wait providing warned listen humanity cure ego usa die racism produced love reading \n",
      "2\t0.1\ttherapeutics ennaid company produced racism usa die ego cure warned listen humanity wait providing medicine immunity fake prevailed reading love \n",
      "\n",
      "<200> LL/token: -7.29691\n",
      "<210> LL/token: -7.26198\n",
      "<220> LL/token: -7.28033\n",
      "<230> LL/token: -7.287\n",
      "<240> LL/token: -7.30608\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid die medicine warned wait immunity produced ego cure racism providing listen usa humanity prevailed fake love reading \n",
      "2\t0.1\ttherapeutics ennaid company fake humanity prevailed usa listen providing racism ego cure produced wait immunity warned medicine die reading love \n",
      "\n",
      "<250> LL/token: -7.29001\n",
      "<260> LL/token: -7.26828\n",
      "<270> LL/token: -7.27867\n",
      "<280> LL/token: -7.27245\n",
      "<290> LL/token: -7.27942\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics ennaid company racism listen cure die prevailed warned ego wait immunity humanity produced fake usa medicine providing reading love \n",
      "2\t0.1\ttherapeutics company ennaid providing medicine usa fake produced humanity wait immunity ego warned prevailed cure die listen racism love reading \n",
      "\n",
      "<300> LL/token: -7.25911\n",
      "<310> LL/token: -7.2937\n",
      "<320> LL/token: -7.29018\n",
      "<330> LL/token: -7.30285\n",
      "<340> LL/token: -7.29656\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics ennaid company racism listen produced wait medicine warned prevailed usa immunity fake providing die cure humanity ego love reading \n",
      "2\t0.1\ttherapeutics company ennaid ego humanity cure providing die usa immunity fake prevailed warned medicine wait listen produced racism reading love \n",
      "\n",
      "<350> LL/token: -7.296\n",
      "<360> LL/token: -7.28931\n",
      "<370> LL/token: -7.28588\n",
      "<380> LL/token: -7.28562\n",
      "<390> LL/token: -7.28965\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid medicine produced prevailed wait humanity cure usa warned fake ego immunity racism die listen providing reading love \n",
      "2\t0.1\ttherapeutics company ennaid providing listen die racism immunity fake ego usa warned wait humanity cure prevailed produced medicine love reading \n",
      "\n",
      "<400> LL/token: -7.28752\n",
      "<410> LL/token: -7.28678\n",
      "<420> LL/token: -7.30161\n",
      "<430> LL/token: -7.29208\n",
      "<440> LL/token: -7.30676\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid wait prevailed fake humanity listen immunity providing usa die produced warned racism cure ego medicine love reading \n",
      "2\t0.1\ttherapeutics ennaid company medicine ego racism cure warned produced usa die listen immunity providing humanity fake prevailed wait reading love \n",
      "\n",
      "<450> LL/token: -7.30588\n",
      "<460> LL/token: -7.29154\n",
      "<470> LL/token: -7.29041\n",
      "<480> LL/token: -7.28974\n",
      "<490> LL/token: -7.30206\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics ennaid company humanity die immunity medicine prevailed racism usa warned listen fake ego cure providing produced wait reading love \n",
      "2\t0.1\ttherapeutics company ennaid wait produced providing cure usa warned listen fake ego racism medicine prevailed immunity die humanity love reading \n",
      "\n",
      "<500> LL/token: -7.29268\n",
      "<510> LL/token: -7.27484\n",
      "<520> LL/token: -7.27358\n",
      "<530> LL/token: -7.29601\n",
      "<540> LL/token: -7.29154\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid humanity die prevailed racism usa fake providing listen wait warned medicine immunity produced cure ego love reading \n",
      "2\t0.1\ttherapeutics ennaid company ego cure wait warned medicine immunity produced listen providing fake usa racism prevailed die humanity reading love \n",
      "\n",
      "<550> LL/token: -7.29497\n",
      "<560> LL/token: -7.29172\n",
      "<570> LL/token: -7.2803\n",
      "<580> LL/token: -7.27843\n",
      "<590> LL/token: -7.27804\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid racism immunity prevailed ego die listen warned usa humanity wait medicine fake produced cure providing reading love \n",
      "2\t0.1\ttherapeutics ennaid company providing cure fake produced wait medicine usa humanity warned listen die ego immunity prevailed racism love reading \n",
      "\n",
      "<600> LL/token: -7.29156\n",
      "<610> LL/token: -7.30099\n",
      "<620> LL/token: -7.30583\n",
      "<630> LL/token: -7.30504\n",
      "<640> LL/token: -7.29013\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid medicine ego produced die providing prevailed cure humanity warned wait usa immunity racism listen fake love reading \n",
      "2\t0.1\ttherapeutics ennaid company listen fake racism usa immunity wait warned humanity cure prevailed providing die ego produced medicine reading love \n",
      "\n",
      "<650> LL/token: -7.28706\n",
      "<660> LL/token: -7.28376\n",
      "<670> LL/token: -7.2768\n",
      "<680> LL/token: -7.28575\n",
      "<690> LL/token: -7.29542\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics ennaid company warned racism providing listen fake wait ego produced immunity die humanity prevailed medicine cure usa love reading \n",
      "2\t0.1\ttherapeutics company ennaid usa cure medicine prevailed humanity immunity die produced wait ego listen fake providing warned racism reading love \n",
      "\n",
      "<700> LL/token: -7.28683\n",
      "<710> LL/token: -7.28615\n",
      "<720> LL/token: -7.29688\n",
      "<730> LL/token: -7.3059\n",
      "<740> LL/token: -7.29228\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid wait warned immunity medicine usa humanity ego providing prevailed produced fake die cure listen racism love reading \n",
      "2\t0.1\ttherapeutics company ennaid listen racism cure fake die prevailed produced providing ego usa humanity medicine warned immunity wait reading love \n",
      "\n",
      "<750> LL/token: -7.28325\n",
      "<760> LL/token: -7.27492\n",
      "<770> LL/token: -7.27334\n",
      "<780> LL/token: -7.3123\n",
      "<790> LL/token: -7.2882\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics ennaid company humanity wait warned produced racism prevailed medicine die ego fake listen providing immunity usa cure love reading \n",
      "2\t0.1\ttherapeutics company ennaid cure usa immunity listen providing fake ego medicine die prevailed racism produced wait warned humanity reading love \n",
      "\n",
      "<800> LL/token: -7.29003\n",
      "<810> LL/token: -7.2806\n",
      "<820> LL/token: -7.28955\n",
      "<830> LL/token: -7.28674\n",
      "<840> LL/token: -7.28756\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid usa ego wait humanity fake racism medicine cure die prevailed immunity listen providing warned produced reading love \n",
      "2\t0.1\ttherapeutics ennaid company produced warned listen providing immunity prevailed die cure medicine racism wait humanity fake usa ego reading love \n",
      "\n",
      "<850> LL/token: -7.29827\n",
      "<860> LL/token: -7.30448\n",
      "<870> LL/token: -7.28488\n",
      "<880> LL/token: -7.27318\n",
      "<890> LL/token: -7.29218\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid medicine humanity warned racism ego cure wait providing prevailed produced fake listen usa die immunity reading love \n",
      "2\t0.1\ttherapeutics ennaid company immunity usa die listen fake wait providing prevailed produced cure ego racism warned humanity medicine love reading \n",
      "\n",
      "<900> LL/token: -7.28116\n",
      "<910> LL/token: -7.29118\n",
      "<920> LL/token: -7.29226\n",
      "<930> LL/token: -7.28599\n",
      "<940> LL/token: -7.28253\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics ennaid company wait listen fake usa providing warned immunity prevailed produced medicine ego cure die racism humanity love reading \n",
      "2\t0.1\ttherapeutics company ennaid humanity racism medicine ego cure die immunity prevailed produced warned usa providing wait listen fake reading love \n",
      "\n",
      "<950> LL/token: -7.28446\n",
      "<960> LL/token: -7.28796\n",
      "<970> LL/token: -7.3027\n",
      "<980> LL/token: -7.29014\n",
      "<990> LL/token: -7.28079\n",
      "\n",
      "0\t0.1\temergency cases school private toll death pharma big \n",
      "1\t0.1\ttherapeutics company ennaid fake racism medicine ego produced wait warned humanity usa immunity cure die listen prevailed providing reading love \n",
      "2\t0.1\ttherapeutics ennaid company providing listen prevailed cure die usa immunity warned humanity wait ego produced medicine racism fake love reading \n",
      "\n",
      "<1000> LL/token: -7.27937\n",
      "\n",
      "Total time: 31 seconds\n",
      "Time Elapsed: 0:00:33.184990\n",
      "Training model: MalletLDA | {'num_topics': 3, 'alpha': 0.6, 'random_seed': 100}\n",
      "Mallet LDA: 3 topics, 2 topic bits, 11 topic mask\n",
      "Data loaded.\n",
      "max tokens: 38\n",
      "total tokens: 16200\n",
      "<10> LL/token: -7.05454\n",
      "<20> LL/token: -6.98662\n",
      "<30> LL/token: -6.96876\n",
      "<40> LL/token: -6.97427\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics company ennaid listen wait prevailed die racism medicine humanity warned immunity providing fake cure produced usa ego love reading \n",
      "2\t0.2\ttherapeutics ennaid company ego usa produced cure fake providing warned immunity humanity medicine racism die wait prevailed listen reading love \n",
      "\n",
      "<50> LL/token: -6.98604\n",
      "<60> LL/token: -6.9872\n",
      "<70> LL/token: -6.95614\n",
      "<80> LL/token: -6.97078\n",
      "<90> LL/token: -6.98577\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics company ennaid listen produced wait warned racism humanity providing die immunity prevailed usa cure fake ego medicine love reading \n",
      "2\t0.2\ttherapeutics ennaid company medicine ego fake usa cure prevailed immunity die providing racism humanity wait warned produced listen reading love \n",
      "\n",
      "<100> LL/token: -6.95291\n",
      "<110> LL/token: -6.97969\n",
      "<120> LL/token: -6.97192\n",
      "<130> LL/token: -6.96389\n",
      "<140> LL/token: -6.97261\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid medicine immunity fake wait usa company listen racism ego providing prevailed produced warned cure die humanity love reading \n",
      "2\t0.2\ttherapeutics company ennaid humanity die cure warned produced providing prevailed ego listen racism wait usa immunity fake medicine reading love \n",
      "\n",
      "<150> LL/token: -6.96652\n",
      "<160> LL/token: -6.99125\n",
      "<170> LL/token: -6.9705\n",
      "<180> LL/token: -6.96168\n",
      "<190> LL/token: -6.96076\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics company ennaid warned wait immunity humanity prevailed ego providing die fake listen medicine produced usa racism cure love reading \n",
      "2\t0.2\ttherapeutics company ennaid racism cure usa produced listen medicine fake die providing ego prevailed wait immunity humanity warned reading love \n",
      "\n",
      "<200> LL/token: -6.96069\n",
      "<210> LL/token: -6.96797\n",
      "<220> LL/token: -6.98715\n",
      "<230> LL/token: -6.94761\n",
      "<240> LL/token: -6.95705\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company immunity racism ego usa cure listen providing humanity wait produced fake prevailed warned die medicine love reading \n",
      "2\t0.2\ttherapeutics company ennaid medicine die warned fake prevailed produced wait humanity listen providing cure usa ego racism immunity reading love \n",
      "\n",
      "<250> LL/token: -6.96024\n",
      "<260> LL/token: -6.96488\n",
      "<270> LL/token: -6.97234\n",
      "<280> LL/token: -6.97126\n",
      "<290> LL/token: -6.96531\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company fake medicine cure humanity immunity die prevailed wait usa providing listen ego warned racism produced reading love \n",
      "2\t0.2\ttherapeutics company ennaid racism produced warned ego listen usa providing wait prevailed immunity die humanity cure medicine fake love reading \n",
      "\n",
      "<300> LL/token: -6.94995\n",
      "<310> LL/token: -6.97488\n",
      "<320> LL/token: -6.96202\n",
      "<330> LL/token: -6.95627\n",
      "<340> LL/token: -6.98252\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company ego wait cure warned medicine immunity racism providing humanity usa fake prevailed listen die produced love reading \n",
      "2\t0.2\ttherapeutics company ennaid produced die listen usa fake prevailed humanity providing immunity racism warned medicine cure wait ego reading love \n",
      "\n",
      "<350> LL/token: -6.99062\n",
      "<360> LL/token: -6.97722\n",
      "<370> LL/token: -6.96254\n",
      "<380> LL/token: -6.94945\n",
      "<390> LL/token: -6.95991\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics company ennaid die listen racism wait immunity humanity cure usa ego produced providing prevailed medicine fake warned reading love \n",
      "2\t0.2\ttherapeutics ennaid company warned medicine fake prevailed providing ego produced usa cure humanity immunity wait racism listen die love reading \n",
      "\n",
      "<400> LL/token: -6.96059\n",
      "<410> LL/token: -6.96215\n",
      "<420> LL/token: -6.96842\n",
      "<430> LL/token: -6.96883\n",
      "<440> LL/token: -6.99924\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company listen fake produced warned prevailed medicine cure immunity usa racism providing ego die wait humanity reading love \n",
      "2\t0.2\ttherapeutics company ennaid humanity wait die ego providing racism usa immunity medicine cure warned prevailed fake produced listen love reading \n",
      "\n",
      "<450> LL/token: -6.96919\n",
      "<460> LL/token: -6.963\n",
      "<470> LL/token: -6.96066\n",
      "<480> LL/token: -6.98087\n",
      "<490> LL/token: -6.9715\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company medicine prevailed die usa ego wait warned cure immunity produced humanity providing fake racism listen reading love \n",
      "2\t0.2\ttherapeutics company ennaid listen racism humanity providing fake immunity produced cure wait warned ego usa die medicine prevailed love reading \n",
      "\n",
      "<500> LL/token: -6.96465\n",
      "<510> LL/token: -6.96225\n",
      "<520> LL/token: -6.95507\n",
      "<530> LL/token: -6.96746\n",
      "<540> LL/token: -6.96911\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company usa medicine produced die prevailed racism cure humanity warned listen ego wait immunity providing fake love reading \n",
      "2\t0.2\ttherapeutics company ennaid immunity providing fake wait ego warned listen humanity racism cure prevailed medicine produced die usa reading love \n",
      "\n",
      "<550> LL/token: -6.985\n",
      "<560> LL/token: -6.96681\n",
      "<570> LL/token: -6.98257\n",
      "<580> LL/token: -6.97889\n",
      "<590> LL/token: -6.97792\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company usa cure medicine humanity wait fake produced racism prevailed immunity ego die listen warned providing love reading \n",
      "2\t0.2\ttherapeutics company ennaid warned providing listen ego die immunity prevailed racism fake produced wait medicine humanity cure usa reading love \n",
      "\n",
      "<600> LL/token: -6.98086\n",
      "<610> LL/token: -6.98322\n",
      "<620> LL/token: -6.98497\n",
      "<630> LL/token: -6.99284\n",
      "<640> LL/token: -6.96881\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics company ennaid humanity die produced listen providing immunity ego usa medicine fake cure wait racism warned prevailed love reading \n",
      "2\t0.2\ttherapeutics ennaid company prevailed warned racism wait cure fake usa medicine immunity ego listen providing produced die humanity reading love \n",
      "\n",
      "<650> LL/token: -6.97334\n",
      "<660> LL/token: -6.97586\n",
      "<670> LL/token: -6.99618\n",
      "<680> LL/token: -6.95619\n",
      "<690> LL/token: -6.97943\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics company ennaid immunity listen racism prevailed produced wait ego warned fake usa medicine providing die cure humanity love reading \n",
      "2\t0.2\ttherapeutics ennaid company humanity cure providing die medicine usa fake warned ego wait prevailed produced racism listen immunity reading love \n",
      "\n",
      "<700> LL/token: -6.9678\n",
      "<710> LL/token: -6.97875\n",
      "<720> LL/token: -6.98881\n",
      "<730> LL/token: -6.96045\n",
      "<740> LL/token: -6.95331\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company die usa prevailed produced immunity medicine fake cure humanity wait listen warned racism providing ego love reading \n",
      "2\t0.2\ttherapeutics company ennaid ego providing warned racism wait listen humanity medicine fake cure immunity prevailed produced usa die reading love \n",
      "\n",
      "<750> LL/token: -6.98364\n",
      "<760> LL/token: -6.97191\n",
      "<770> LL/token: -6.96461\n",
      "<780> LL/token: -6.96188\n",
      "<790> LL/token: -6.97307\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company warned medicine prevailed die fake produced listen humanity providing ego cure wait racism immunity usa reading love \n",
      "2\t0.2\ttherapeutics company ennaid usa immunity racism wait cure ego humanity providing listen fake produced die prevailed medicine warned love reading \n",
      "\n",
      "<800> LL/token: -6.96023\n",
      "<810> LL/token: -6.96469\n",
      "<820> LL/token: -6.97105\n",
      "<830> LL/token: -6.95941\n",
      "<840> LL/token: -6.97454\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company wait warned fake usa die ego medicine providing humanity produced listen immunity racism prevailed cure love reading \n",
      "2\t0.2\ttherapeutics company ennaid cure prevailed racism listen immunity humanity produced medicine providing ego usa die warned fake wait reading love \n",
      "\n",
      "<850> LL/token: -6.97517\n",
      "<860> LL/token: -6.97478\n",
      "<870> LL/token: -6.9404\n",
      "<880> LL/token: -6.93849\n",
      "<890> LL/token: -6.94801\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company immunity die prevailed usa humanity ego produced fake medicine providing warned listen racism cure wait love reading \n",
      "2\t0.2\ttherapeutics company ennaid wait cure warned listen racism medicine providing fake ego produced usa humanity prevailed die immunity reading love \n",
      "\n",
      "<900> LL/token: -6.96014\n",
      "<910> LL/token: -6.97386\n",
      "<920> LL/token: -6.9881\n",
      "<930> LL/token: -6.96657\n",
      "<940> LL/token: -6.97115\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics company ennaid racism providing cure warned medicine immunity wait prevailed ego humanity listen die produced usa fake reading love \n",
      "2\t0.2\ttherapeutics ennaid company usa fake produced listen die humanity ego wait prevailed immunity warned medicine providing cure racism love reading \n",
      "\n",
      "<950> LL/token: -6.94476\n",
      "<960> LL/token: -6.9515\n",
      "<970> LL/token: -6.96337\n",
      "<980> LL/token: -6.94805\n",
      "<990> LL/token: -6.95804\n",
      "\n",
      "0\t0.2\temergency cases school private toll death pharma big \n",
      "1\t0.2\ttherapeutics ennaid company usa immunity warned cure wait produced fake humanity ego medicine providing prevailed racism die listen reading love \n",
      "2\t0.2\ttherapeutics company ennaid listen die racism medicine providing prevailed humanity ego fake wait produced cure warned immunity usa love reading \n",
      "\n",
      "<1000> LL/token: -6.96452\n",
      "\n",
      "Total time: 32 seconds\n",
      "Time Elapsed: 0:00:33.602640\n",
      "Training model: MalletLDA | {'num_topics': 3, 'alpha': 'symmetric', 'random_seed': 100}\n",
      "\n",
      "For input string: \"symmetric\"\n"
     ]
    }
   ],
   "source": [
    "results_digrams = pipeline.choose_lda_models(tweets_negneut['digrams'],n_grams=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     LDA Model                                             Params  \\\n",
       "223  GensimLDA  {'chunksize': 2000, 'num_topics': 15, 'alpha':...   \n",
       "106  GensimLDA  {'chunksize': 1000, 'num_topics': 15, 'alpha':...   \n",
       "225  GensimLDA  {'chunksize': 2000, 'num_topics': 15, 'alpha':...   \n",
       "222  GensimLDA  {'chunksize': 2000, 'num_topics': 15, 'alpha':...   \n",
       "226  GensimLDA  {'chunksize': 2000, 'num_topics': 15, 'alpha':...   \n",
       "..         ...                                                ...   \n",
       "115  GensimLDA  {'chunksize': 1000, 'num_topics': 15, 'alpha':...   \n",
       "108  GensimLDA  {'chunksize': 1000, 'num_topics': 15, 'alpha':...   \n",
       "240  MalletLDA  {'num_topics': 3, 'alpha': 0.1, 'random_seed':...   \n",
       "241  MalletLDA  {'num_topics': 3, 'alpha': 0.3, 'random_seed':...   \n",
       "242  MalletLDA  {'num_topics': 3, 'alpha': 0.6, 'random_seed':...   \n",
       "\n",
       "              Time Elapsed  Coherence Perplexity  \\\n",
       "223 0 days 00:00:15.596471   0.834583  -3.466491   \n",
       "106 0 days 00:00:17.894784   0.826759   -3.50214   \n",
       "225 0 days 00:00:16.542957   0.812004  -3.499362   \n",
       "222 0 days 00:00:15.557326   0.810889  -3.447349   \n",
       "226 0 days 00:00:16.240618   0.807441  -3.507713   \n",
       "..                     ...        ...        ...   \n",
       "115 0 days 00:00:15.860674   0.636405  -3.059438   \n",
       "108 0 days 00:00:16.828274   0.635639  -3.161513   \n",
       "240 0 days 00:00:33.160030   0.591153        N/A   \n",
       "241 0 days 00:00:33.184990   0.591153        N/A   \n",
       "242 0 days 00:00:33.602640   0.591153        N/A   \n",
       "\n",
       "                                                Topics  \n",
       "223  [(0, 0.517*\"ennaid therapeutics\" + 0.450*\"ther...  \n",
       "106  [(0, 0.902*\"death toll\" + 0.025*\"new cases\" + ...  \n",
       "225  [(0, 0.186*\"ennaid therapeutics\" + 0.175*\"ther...  \n",
       "222  [(0, 0.976*\"new cases\" + 0.001*\"death toll\" + ...  \n",
       "226  [(0, 0.088*\"ennaid therapeutics\" + 0.087*\"ther...  \n",
       "..                                                 ...  \n",
       "115  [(0, 0.982*\"emergency use\" + 0.001*\"big pharma...  \n",
       "108  [(0, 0.040*\"providing immunity\" + 0.040*\"readi...  \n",
       "240  [(0, nan*\"providing immunity\" + nan*\"reading f...  \n",
       "241  [(0, nan*\"providing immunity\" + nan*\"reading f...  \n",
       "242  [(0, nan*\"providing immunity\" + nan*\"reading f...  \n",
       "\n",
       "[243 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LDA Model</th>\n      <th>Params</th>\n      <th>Time Elapsed</th>\n      <th>Coherence</th>\n      <th>Perplexity</th>\n      <th>Topics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>223</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 2000, 'num_topics': 15, 'alpha':...</td>\n      <td>0 days 00:00:15.596471</td>\n      <td>0.834583</td>\n      <td>-3.466491</td>\n      <td>[(0, 0.517*\"ennaid therapeutics\" + 0.450*\"ther...</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 15, 'alpha':...</td>\n      <td>0 days 00:00:17.894784</td>\n      <td>0.826759</td>\n      <td>-3.50214</td>\n      <td>[(0, 0.902*\"death toll\" + 0.025*\"new cases\" + ...</td>\n    </tr>\n    <tr>\n      <th>225</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 2000, 'num_topics': 15, 'alpha':...</td>\n      <td>0 days 00:00:16.542957</td>\n      <td>0.812004</td>\n      <td>-3.499362</td>\n      <td>[(0, 0.186*\"ennaid therapeutics\" + 0.175*\"ther...</td>\n    </tr>\n    <tr>\n      <th>222</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 2000, 'num_topics': 15, 'alpha':...</td>\n      <td>0 days 00:00:15.557326</td>\n      <td>0.810889</td>\n      <td>-3.447349</td>\n      <td>[(0, 0.976*\"new cases\" + 0.001*\"death toll\" + ...</td>\n    </tr>\n    <tr>\n      <th>226</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 2000, 'num_topics': 15, 'alpha':...</td>\n      <td>0 days 00:00:16.240618</td>\n      <td>0.807441</td>\n      <td>-3.507713</td>\n      <td>[(0, 0.088*\"ennaid therapeutics\" + 0.087*\"ther...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 15, 'alpha':...</td>\n      <td>0 days 00:00:15.860674</td>\n      <td>0.636405</td>\n      <td>-3.059438</td>\n      <td>[(0, 0.982*\"emergency use\" + 0.001*\"big pharma...</td>\n    </tr>\n    <tr>\n      <th>108</th>\n      <td>GensimLDA</td>\n      <td>{'chunksize': 1000, 'num_topics': 15, 'alpha':...</td>\n      <td>0 days 00:00:16.828274</td>\n      <td>0.635639</td>\n      <td>-3.161513</td>\n      <td>[(0, 0.040*\"providing immunity\" + 0.040*\"readi...</td>\n    </tr>\n    <tr>\n      <th>240</th>\n      <td>MalletLDA</td>\n      <td>{'num_topics': 3, 'alpha': 0.1, 'random_seed':...</td>\n      <td>0 days 00:00:33.160030</td>\n      <td>0.591153</td>\n      <td>N/A</td>\n      <td>[(0, nan*\"providing immunity\" + nan*\"reading f...</td>\n    </tr>\n    <tr>\n      <th>241</th>\n      <td>MalletLDA</td>\n      <td>{'num_topics': 3, 'alpha': 0.3, 'random_seed':...</td>\n      <td>0 days 00:00:33.184990</td>\n      <td>0.591153</td>\n      <td>N/A</td>\n      <td>[(0, nan*\"providing immunity\" + nan*\"reading f...</td>\n    </tr>\n    <tr>\n      <th>242</th>\n      <td>MalletLDA</td>\n      <td>{'num_topics': 3, 'alpha': 0.6, 'random_seed':...</td>\n      <td>0 days 00:00:33.602640</td>\n      <td>0.591153</td>\n      <td>N/A</td>\n      <td>[(0, nan*\"providing immunity\" + nan*\"reading f...</td>\n    </tr>\n  </tbody>\n</table>\n<p>243 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "results_digrams.sort_values('Coherence',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_digrams.to_csv('lda_models_gs_digrams_3day.csv')"
   ]
  },
  {
   "source": [
    "Once the ideal parameters are selected, we can manually create the models to consider specific aspects more in-depth (and to create the dynamic visualizations below). First, we use Gensim to create a dictionary of the unique words that appear mapped to an id. (We are still filtering out from the dictionary words that don't appear enough or appear in too many tweets.) Second, we'll create a corpus of the tweets, which contains the number of times a given word (identified by id) appeared in each tweet. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "tweets_nn_lst = []\n",
    "for tweet in tweets_negneut['text_cln_tok']:\n",
    "    tweets_nn_lst.append(ast.literal_eval(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_nn_di_lst = []\n",
    "for tweet in tweets_negneut['digrams']:\n",
    "    tweets_nn_di_lst.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dict = corpora.Dictionary(tweets_nn_di_lst)\n",
    "single_dict.filter_extremes(no_below=100, no_above=0.80, keep_n=1000000)\n",
    "\n",
    "single_corpus = [single_dict.doc2bow(tweet) for tweet in tweets_nn_di_lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dict = corpora.Dictionary(tweets_nn_lst)\n",
    "single_dict.filter_extremes(no_below=100, no_above=0.80, keep_n=1000000)\n",
    "\n",
    "single_corpus = [single_dict.doc2bow(tweet) for tweet in tweets_nn_lst]"
   ]
  },
  {
   "source": [
    "To see the dictionary and corpus contents, run the below 2 cells:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'people': 0, 'week': 1, 'world': 2, 'cases': 3, 'india': 4, 'age': 5, 'years': 6, 'doses': 7, 'getting': 8, 'need': 9, 'pfizer': 10, 'shot': 11, 'new': 12, 'appointments': 13, 'available': 14, 'near': 15, 'sign': 16, 'know': 17, 'today': 18, 'government': 19, 'adults': 20, 'april': 21, 'eligible': 22, 'dose': 23, 'says': 24, 'health': 25, 'news': 26, 'astrazeneca': 27, 'received': 28, 'second': 29, 'pandemic': 30, 'states': 31}\n"
     ]
    }
   ],
   "source": [
    "print(single_dict.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]\n",
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(single_corpus[0])"
   ]
  },
  {
   "source": [
    "Next, we can train the model with the parameters we identified above (or, with any other parameters)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "single_model = gensim.models.ldamodel.LdaModel(corpus=single_corpus,\n",
    "                                           id2word=single_dict,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=2000,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.1,\n",
    "                                           eta=1,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.072*\"available\" + 0.071*\"covid\" + 0.071*\"19\" + 0.069*\"vaccination\" + 0.068*\"appointments\" + 0.058*\"sign\" + 0.057*\"near\" + 0.056*\"04\" + 0.054*\"00\" + 0.052*\"cvs\"'),\n",
       " (1,\n",
       "  '0.040*\"dose\" + 0.038*\"cases\" + 0.036*\"doses\" + 0.025*\"covid19\" + 0.022*\"people\" + 0.021*\"vaccinated\" + 0.020*\"million\" + 0.020*\"new\" + 0.020*\"received\" + 0.018*\"deaths\"'),\n",
       " (2,\n",
       "  '0.020*\"covid19\" + 0.020*\"vaccines\" + 0.020*\"people\" + 0.013*\"t\" + 0.013*\"vaccinated\" + 0.012*\"vaccine\" + 0.009*\"india\" + 0.008*\"need\" + 0.007*\"getting\" + 0.007*\"know\"'),\n",
       " (3,\n",
       "  '0.108*\"covid\" + 0.102*\"vaccine\" + 0.097*\"19\" + 0.038*\"johnson\" + 0.029*\"s\" + 0.020*\"j\" + 0.020*\"vaccines\" + 0.019*\"coronavirus\" + 0.018*\"covid19\" + 0.016*\"vaccination\"'),\n",
       " (4,\n",
       "  '0.019*\"eligible\" + 0.017*\"april\" + 0.014*\"today\" + 0.014*\"state\" + 0.014*\"appointment\" + 0.013*\"age\" + 0.012*\"health\" + 0.012*\"county\" + 0.011*\"receive\" + 0.010*\"students\"')]"
      ]
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "# View the topics identified in the above model\n",
    "single_model.print_topics()"
   ]
  },
  {
   "source": [
    "We can use Coherence as one method for considering our model's accuracy:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  \n",
      "0.3935333507272311\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "single_coherence_model_lda = CoherenceModel(model=single_model, texts=tweets_nn_lst, dictionary=single_dict, coherence='c_v')\n",
    "single_coherence_lda = single_coherence_model_lda.get_coherence()\n",
    "print(single_coherence_lda)"
   ]
  },
  {
   "source": [
    "We can also visualize the topics and their overlap:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.347104 -0.270027       1        1  21.493818\n",
       "0      0.235138 -0.113997       2        1  18.678340\n",
       "2      0.012179  0.129301       3        1  18.054852\n",
       "1      0.228433 -0.177726       4        1  15.699520\n",
       "5     -0.063569  0.161599       5        1  15.486252\n",
       "4     -0.065077  0.270850       6        1  10.587218, topic_info=             Term         Freq        Total Category  logprob  loglift\n",
       "22         people  2828.000000  2828.000000  Default  30.0000  30.0000\n",
       "1       available  2638.000000  2638.000000  Default  29.0000  29.0000\n",
       "0    appointments  2389.000000  2389.000000  Default  28.0000  28.0000\n",
       "550          near  2360.000000  2360.000000  Default  27.0000  27.0000\n",
       "4            sign  2325.000000  2325.000000  Default  26.0000  26.0000\n",
       "..            ...          ...          ...      ...      ...      ...\n",
       "133        taking   107.510772   108.402962   Topic6  -4.6140   2.2373\n",
       "266          lakh   104.460851   105.362945   Topic6  -4.6428   2.2369\n",
       "540    infections   102.652038   103.545210   Topic6  -4.6603   2.2369\n",
       "204         march   102.509339   103.401968   Topic6  -4.6617   2.2369\n",
       "476          laws   276.449312   292.496050   Topic6  -3.6696   2.1891\n",
       "\n",
       "[213 rows x 6 columns], token_table=      Topic      Freq          Term\n",
       "term                               \n",
       "87        4  0.996178        access\n",
       "434       3  0.995897     according\n",
       "177       6  0.996760        active\n",
       "479       4  0.996811  administered\n",
       "622       4  0.997940   administers\n",
       "...     ...       ...           ...\n",
       "148       5  0.997105         world\n",
       "83        1  0.995938         wrong\n",
       "102       6  0.996099          year\n",
       "149       3  0.997375           you\n",
       "263       3  0.997551         young\n",
       "\n",
       "[189 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 2, 6, 5])"
      ],
      "text/html": "\n<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n\n\n<div id=\"ldavis_el19731397749451037602771054418\"></div>\n<script type=\"text/javascript\">\n\nvar ldavis_el19731397749451037602771054418_data = {\"mdsDat\": {\"x\": [-0.3471043460376804, 0.23513812647986368, 0.012179097992583416, 0.22843271946455693, -0.06356884384769389, -0.06507675405162956], \"y\": [-0.27002684721079884, -0.1139974620268362, 0.12930083808831133, -0.17772581548581112, 0.16159919146942556, 0.2708500951657097], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [21.493818268958382, 18.678339604352335, 18.05485156589462, 15.699519894652322, 15.486252271476515, 10.587218394665827]}, \"tinfo\": {\"Term\": [\"people\", \"available\", \"appointments\", \"near\", \"sign\", \"cvs\", \"india\", \"cases\", \"new\", \"health\", \"total\", \"situation\", \"doses\", \"fully\", \"time\", \"nation\", \"pfizer\", \"deaths\", \"death\", \"dose\", \"getting\", \"virus\", \"times\", \"news\", \"need\", \"going\", \"soon\", \"lack\", \"modi\", \"million\", \"available\", \"appointments\", \"near\", \"sign\", \"cvs\", \"canada\", \"risk\", \"johnson\", \"says\", \"future\", \"cdc\", \"check\", \"wrong\", \"appointment\", \"rate\", \"disease\", \"variants\", \"workers\", \"shows\", \"high\", \"doesn\", \"study\", \"research\", \"latest\", \"vax\", \"trump\", \"ages\", \"sites\", \"based\", \"developed\", \"nation\", \"pfizer\", \"dose\", \"getting\", \"need\", \"going\", \"black\", \"govt\", \"today\", \"second\", \"shot\", \"present\", \"days\", \"tested\", \"drive\", \"data\", \"saturday\", \"weeks\", \"said\", \"age\", \"experts\", \"live\", \"start\", \"adults\", \"think\", \"now\", \"group\", \"here\", \"trials\", \"update\", \"farm\", \"news\", \"india\", \"situation\", \"time\", \"soon\", \"modi\", \"fight\", \"pandemic\", \"tough\", \"global\", \"outbreak\", \"you\", \"indian\", \"public\", \"stop\", \"countries\", \"mass\", \"spread\", \"way\", \"according\", \"effects\", \"read\", \"life\", \"china\", \"possible\", \"coming\", \"biden\", \"die\", \"young\", \"daily\", \"continue\", \"people\", \"doses\", \"lack\", \"know\", \"country\", \"government\", \"anti\", \"administered\", \"dont\", \"doctor\", \"mask\", \"access\", \"states\", \"oxygen\", \"don\", \"dies\", \"like\", \"months\", \"children\", \"hospitals\", \"administers\", \"fake\", \"blood\", \"want\", \"long\", \"testing\", \"shots\", \"wear\", \"reactions\", \"kenyan\", \"health\", \"fully\", \"times\", \"million\", \"world\", \"dying\", \"food\", \"use\", \"stand\", \"americans\", \"passed\", \"australia\", \"moderna\", \"population\", \"emergency\", \"received\", \"county\", \"supply\", \"positive\", \"astrazeneca\", \"work\", \"sick\", \"center\", \"died\", \"april\", \"jab\", \"centre\", \"masks\", \"mrna\", \"city\", \"cases\", \"new\", \"total\", \"deaths\", \"death\", \"virus\", \"reports\", \"state\", \"got\", \"hours\", \"recoveries\", \"toll\", \"active\", \"year\", \"immunity\", \"ministry\", \"union\", \"discharges\", \"dead\", \"day\", \"right\", \"look\", \"reported\", \"wait\", \"flu\", \"spike\", \"taking\", \"lakh\", \"infections\", \"march\", \"laws\"], \"Freq\": [2828.0, 2638.0, 2389.0, 2360.0, 2325.0, 2317.0, 1914.0, 1243.0, 983.0, 965.0, 768.0, 905.0, 835.0, 740.0, 753.0, 728.0, 701.0, 519.0, 500.0, 663.0, 628.0, 457.0, 542.0, 730.0, 539.0, 538.0, 527.0, 459.0, 494.0, 446.0, 2637.7353808367484, 2388.2918290007246, 2359.6473445334977, 2324.992061373677, 2316.215730888246, 299.96838291566854, 292.5703064540705, 261.02809232724877, 253.99127330017558, 289.4365033156893, 210.99790604256876, 207.06105110948465, 207.95052577271377, 198.2707748360619, 188.02355337921105, 188.70976818245853, 179.1838721009759, 178.11377897474017, 177.84833730712415, 168.69784953327584, 166.17330300778997, 158.44365518242907, 144.78518118594982, 128.49905412114768, 127.10398311767764, 122.70897828629266, 121.23878460427227, 114.36012721983641, 112.53754603462416, 110.65010668099376, 727.1764806612885, 701.1547197292915, 662.3118836808006, 628.1377245671613, 538.7891642497315, 538.0979876239588, 439.60027479746105, 421.0995107398539, 417.4437349537095, 413.5041957145315, 386.36534564573316, 358.8268884833585, 329.6796304853256, 292.2398391447908, 280.7005115335555, 272.8445126728152, 270.70721532690305, 262.80382750613154, 255.19616176651743, 230.61551354496882, 220.49081500574397, 218.25569216091824, 214.6873337681372, 208.17784791876824, 204.86288412310017, 203.35242562721322, 202.78261749253207, 194.48963859756657, 186.17393652695617, 176.78650256034143, 341.7916355891078, 625.2409206696549, 1914.1291593795763, 904.778466870277, 753.1483744772229, 526.2827241743305, 493.9312633793548, 447.9131954839935, 385.9898468793757, 389.8132843407073, 332.36655941176474, 330.3752338265657, 288.94052928891557, 273.94086483933387, 264.4044253550006, 260.87185180449757, 248.57615019427547, 247.3264552274827, 215.7462902756495, 213.5651727154683, 211.0287960005188, 194.39284116700946, 189.56007974977064, 188.09662978383304, 187.34788433510383, 187.80485283182497, 184.62617748791706, 177.57431255199327, 174.71744115586307, 171.59444409670985, 169.2953374980742, 169.93508650260696, 2827.2769676852577, 834.5133224426725, 458.1874345383925, 418.23954792296075, 388.77409839711083, 368.2867213450998, 330.963241389494, 288.0762518020511, 259.87123530647045, 254.56199334423704, 246.02925629809027, 239.06612103636337, 227.69779165782842, 227.29204792630463, 217.76797555324427, 213.44392718677457, 205.00508372806013, 204.88485559584385, 194.5600812388283, 186.06894318634772, 184.5397420090282, 172.8451668677798, 169.71776740661352, 168.52998656189723, 163.20025218938818, 155.35621292278833, 152.17602453339748, 149.28866190136569, 147.18194325814363, 145.6963633518201, 964.8954767285944, 739.7060504766035, 541.6979988995481, 445.3387312694357, 433.4119485791834, 405.5900490774402, 409.2457453771969, 394.14952621464437, 374.48531946306923, 357.89388236140394, 365.9579522154141, 343.11928503562115, 337.2112310872929, 315.211180360869, 304.2728166683746, 282.74466316601934, 272.2461615904487, 247.8304007664277, 239.96087621715478, 235.99678290576432, 229.97000105803124, 205.7706249706479, 204.98533633170976, 203.6985091287894, 199.2663013366094, 194.52334709458708, 182.45454899161797, 178.53147480266034, 176.75534384605103, 166.5291850102352, 1242.6956579633415, 982.1104884599673, 767.8254931828751, 518.269198690188, 499.52498836237896, 457.0697938263668, 346.5236072673206, 309.95567042594604, 271.780301346972, 269.9134930951658, 260.23299756821, 260.02504015161634, 244.90362864258373, 244.06355583757392, 240.2189196114139, 211.47406479878026, 207.75877311561382, 225.2109522774686, 197.07471586738706, 186.32220824245582, 177.62618187302084, 165.83773598352786, 121.07701840676323, 117.62618398625133, 116.41884702901764, 108.77924554810492, 107.5107719793282, 104.46085109191424, 102.65203776523502, 102.50933852950187, 276.4493120479472], \"Total\": [2828.0, 2638.0, 2389.0, 2360.0, 2325.0, 2317.0, 1914.0, 1243.0, 983.0, 965.0, 768.0, 905.0, 835.0, 740.0, 753.0, 728.0, 701.0, 519.0, 500.0, 663.0, 628.0, 457.0, 542.0, 730.0, 539.0, 538.0, 527.0, 459.0, 494.0, 446.0, 2638.623456616976, 2389.179456368598, 2360.5350535331922, 2325.8796300724275, 2317.103271527123, 300.8634506131959, 293.4685003859281, 261.91687584541984, 254.88322127256748, 290.4612010829543, 211.89094039599328, 207.95080029712975, 208.84833688671995, 199.1616767673403, 188.91700691802407, 189.60992858701715, 180.07721137618438, 179.01032919347932, 178.74749677736668, 169.5977739821312, 167.08325560701792, 159.3375449071675, 145.6999354768229, 129.40225205670498, 127.9990400510728, 123.60219581433432, 122.13620096921267, 115.24992690045568, 113.43833956707411, 111.54270869654013, 728.0289088683152, 701.9938802356934, 663.1507703793364, 628.9782549316587, 539.630138067041, 538.941291932736, 440.4481618442043, 421.9459604833853, 418.28492088085585, 414.34364496363514, 387.20483815430845, 359.6846427394873, 330.52103792596137, 293.08187173866486, 281.5404508485483, 273.6850014487005, 271.54977357774004, 263.64612741977936, 256.03620078783314, 231.4541556742244, 221.33470152449414, 219.09539505582626, 215.529134772338, 209.01621048186695, 205.70410331295312, 204.1922375110611, 203.6209851151362, 195.32962228278078, 187.01784642578835, 177.628718091046, 366.32216166078393, 730.8427303874748, 1914.9588767358082, 905.6127755001618, 753.9733823460352, 527.1130038605539, 494.7595337894396, 448.7362038940716, 386.8116846012245, 390.65541465083186, 333.18705900834834, 331.19775902963136, 289.76064507603616, 274.76135799518465, 265.22763898222206, 261.69603171554826, 249.3991714206605, 248.15194374656136, 216.56796591668657, 214.3890577874633, 211.8693095326026, 195.21554827337377, 190.38638198866298, 188.92256853573676, 188.1711451552285, 188.6307083543652, 185.45236769446706, 178.39894883887405, 175.53790210820335, 172.42232311077706, 170.11771077105016, 170.76170498627798, 2828.1255301209458, 835.3568499203187, 459.0474944779674, 419.08511105820423, 389.61967803124526, 369.131552557967, 331.8050652354794, 288.92146916625427, 260.7169139334249, 255.40425995864953, 246.8728214840617, 239.91697977304997, 228.54145883386414, 228.13697611231277, 218.61189478354572, 214.28461230868504, 205.84862893195609, 205.7338368868006, 195.4049449032379, 186.91261358137166, 185.38188426569337, 173.69439869307223, 170.56266375281956, 169.37390759338422, 164.0456837459648, 156.2030074681691, 153.02066100366582, 150.13176458241415, 148.02550432296445, 146.53597740524913, 965.7512690695, 740.5512772739859, 542.5464487506828, 446.18211529036967, 434.25730750256565, 406.4415662810131, 410.11397782372046, 394.9919800320634, 375.36103236040964, 358.7368476544979, 366.82775342100047, 343.96749553275043, 338.05300073851544, 316.0564600834391, 305.11447399589684, 283.5889399292422, 273.08992049138584, 248.6760352697824, 240.80327177509238, 236.84103486721412, 230.8179664857244, 206.6221980214593, 205.83375649928988, 204.542582869413, 200.11199541525914, 195.36753415615917, 183.30293516344184, 179.37922035996488, 177.60053881337706, 167.37384107552177, 1243.5867229404441, 983.0016098793018, 768.7182090649632, 519.1588087510074, 500.41861543456974, 457.9623691353145, 347.41396377986325, 310.85049602268, 272.6738431697869, 270.8050096073757, 261.1267131739568, 260.93012884711305, 245.79646451637566, 244.95555513218193, 241.1108643045887, 212.36608614719677, 208.65401638161717, 226.18631312847825, 197.96552788984474, 187.21423804777265, 178.51956429582305, 166.73170833171392, 121.96858926151633, 118.51774717602585, 117.3095011131604, 109.66993202587582, 108.40296245828121, 105.36294546299075, 103.54521049054405, 103.40196812556495, 292.4960497305497], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.1221, -2.2214, -2.2335, -2.2483, -2.2521, -4.2961, -4.321, -4.4351, -4.4624, -4.3318, -4.6479, -4.6667, -4.6624, -4.7101, -4.7632, -4.7595, -4.8113, -4.8173, -4.8188, -4.8716, -4.8867, -4.9343, -5.0245, -5.1438, -5.1547, -5.1899, -5.202, -5.2604, -5.2765, -5.2934, -3.2702, -3.3066, -3.3636, -3.4166, -3.57, -3.5713, -3.7735, -3.8165, -3.8252, -3.8347, -3.9026, -3.9765, -4.0612, -4.1818, -4.2221, -4.2504, -4.2583, -4.2879, -4.3173, -4.4186, -4.4635, -4.4737, -4.4902, -4.521, -4.537, -4.5444, -4.5472, -4.589, -4.6327, -4.6844, -4.0251, -3.4212, -2.2684, -3.0177, -3.2011, -3.5596, -3.623, -3.7208, -3.8696, -3.8597, -4.0192, -4.0252, -4.1592, -4.2125, -4.2479, -4.2614, -4.3096, -4.3147, -4.4513, -4.4615, -4.4734, -4.5555, -4.5807, -4.5884, -4.5924, -4.59, -4.6071, -4.646, -4.6622, -4.6803, -4.6937, -4.69, -1.7385, -2.9588, -3.5583, -3.6496, -3.7226, -3.7767, -3.8836, -4.0224, -4.1254, -4.1461, -4.1802, -4.2089, -4.2576, -4.2594, -4.3022, -4.3222, -4.3626, -4.3632, -4.4149, -4.4595, -4.4677, -4.5332, -4.5515, -4.5585, -4.5906, -4.6399, -4.6606, -4.6797, -4.6939, -4.7041, -2.7999, -3.0657, -3.3772, -3.5731, -3.6002, -3.6666, -3.6576, -3.6952, -3.7464, -3.7917, -3.7694, -3.8339, -3.8512, -3.9187, -3.954, -4.0274, -4.0652, -4.1592, -4.1915, -4.2081, -4.234, -4.3452, -4.349, -4.3553, -4.3773, -4.4014, -4.4654, -4.4872, -4.4972, -4.5568, -2.1666, -2.4019, -2.6481, -3.0411, -3.078, -3.1668, -3.4437, -3.5552, -3.6866, -3.6935, -3.73, -3.7308, -3.7908, -3.7942, -3.8101, -3.9375, -3.9552, -3.8746, -4.008, -4.0641, -4.1119, -4.1806, -4.4952, -4.5241, -4.5344, -4.6023, -4.614, -4.6428, -4.6603, -4.6617, -3.6696], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.5371, 1.537, 1.537, 1.537, 1.537, 1.5344, 1.5343, 1.534, 1.5339, 1.5339, 1.5332, 1.5331, 1.5331, 1.5329, 1.5327, 1.5326, 1.5324, 1.5324, 1.5324, 1.5321, 1.5319, 1.5318, 1.5311, 1.5304, 1.5304, 1.5302, 1.53, 1.5297, 1.5294, 1.5294, 1.6766, 1.6766, 1.6765, 1.6765, 1.6762, 1.6762, 1.6759, 1.6758, 1.6758, 1.6758, 1.6756, 1.6754, 1.6753, 1.6749, 1.6748, 1.6747, 1.6747, 1.6746, 1.6745, 1.6742, 1.674, 1.674, 1.6739, 1.6738, 1.6737, 1.6737, 1.6737, 1.6735, 1.6733, 1.6731, 1.6085, 1.5217, 1.7113, 1.7108, 1.7107, 1.7102, 1.7101, 1.7099, 1.7096, 1.7096, 1.7093, 1.7093, 1.7089, 1.7088, 1.7086, 1.7086, 1.7085, 1.7084, 1.708, 1.7079, 1.7078, 1.7075, 1.7074, 1.7074, 1.7074, 1.7074, 1.7073, 1.7071, 1.7071, 1.7069, 1.7069, 1.7069, 1.8512, 1.8505, 1.8497, 1.8495, 1.8494, 1.8492, 1.849, 1.8486, 1.8483, 1.8482, 1.8481, 1.848, 1.8478, 1.8478, 1.8477, 1.8476, 1.8474, 1.8474, 1.8472, 1.847, 1.847, 1.8466, 1.8466, 1.8465, 1.8464, 1.8461, 1.846, 1.8459, 1.8458, 1.8458, 1.8643, 1.8641, 1.8637, 1.8633, 1.8633, 1.8631, 1.8631, 1.8631, 1.8629, 1.8629, 1.8628, 1.8627, 1.8627, 1.8625, 1.8625, 1.8622, 1.8621, 1.8618, 1.8617, 1.8616, 1.8615, 1.8611, 1.8611, 1.8611, 1.861, 1.8609, 1.8606, 1.8605, 1.8604, 1.8602, 2.2448, 2.2446, 2.2444, 2.2438, 2.2437, 2.2436, 2.243, 2.2426, 2.2422, 2.2422, 2.2421, 2.242, 2.2419, 2.2419, 2.2418, 2.2413, 2.2412, 2.2412, 2.241, 2.2407, 2.2405, 2.2401, 2.2382, 2.238, 2.2379, 2.2374, 2.2373, 2.2369, 2.2369, 2.2369, 2.1891]}, \"token.table\": {\"Topic\": [4, 3, 6, 4, 4, 2, 2, 1, 5, 4, 1, 1, 5, 5, 5, 1, 1, 3, 2, 4, 1, 6, 1, 5, 5, 1, 4, 3, 5, 3, 3, 3, 4, 5, 1, 3, 2, 6, 2, 6, 6, 6, 1, 3, 5, 4, 6, 1, 4, 1, 4, 4, 2, 4, 2, 5, 3, 5, 2, 4, 2, 3, 6, 3, 6, 5, 5, 1, 2, 3, 2, 6, 4, 2, 2, 5, 2, 1, 4, 6, 6, 3, 3, 6, 5, 1, 4, 4, 4, 6, 1, 2, 3, 5, 6, 3, 4, 2, 4, 6, 6, 4, 5, 3, 5, 6, 5, 3, 4, 5, 2, 1, 2, 6, 2, 4, 2, 3, 4, 3, 5, 4, 2, 5, 5, 3, 2, 3, 1, 4, 3, 5, 6, 6, 6, 1, 6, 1, 2, 2, 1, 2, 2, 4, 1, 5, 1, 1, 3, 3, 6, 3, 5, 2, 6, 4, 3, 1, 5, 6, 2, 4, 2, 3, 5, 2, 6, 6, 3, 2, 1, 6, 2, 5, 1, 1, 6, 6, 4, 3, 4, 2, 5, 1, 5, 1, 6, 3, 3], \"Freq\": [0.9961779288238899, 0.9958969539546791, 0.9967596583704214, 0.9968106587270466, 0.9979400130319851, 0.9951381259878161, 0.9980378158564427, 0.9906972628901478, 0.9979459939526268, 0.9975736800916284, 0.9941671671669174, 0.9995063341242726, 0.9944431346409214, 0.9964489478451838, 0.9971872472099379, 0.9997637189893797, 0.9961358781453696, 0.9977637265159316, 0.9989824867418499, 0.9967011317691721, 0.9971300913705667, 0.9995282010256133, 0.9957952879234561, 0.9959493694646109, 0.9928919023458076, 0.995427763222016, 0.9979276629696427, 0.9937761703354552, 0.9977664306852283, 0.9975607337879215, 0.9955393688160985, 0.9983994677352507, 0.9984095309703644, 0.9960089318220728, 0.9995238574211688, 0.9934297800858936, 0.9974971173243891, 0.9935141789404778, 0.9984235861982315, 0.9951227473786144, 0.9991634695000181, 0.9977679108367721, 0.9951345210916779, 0.9969356925100324, 0.9973473353968577, 0.9940051117304004, 0.9947551506894036, 0.9967832455211477, 0.9984171761320074, 0.9935166716552032, 0.9972009995880985, 0.997250220852154, 0.9982646926902035, 0.9995728173889366, 0.9980803794022515, 0.9989135799149347, 0.9937733019519964, 0.996347357825077, 0.9939697593043428, 0.9960021814272821, 0.9336044492898948, 0.06278626413353093, 0.002729837571023084, 0.9983593837811995, 0.9888372118137541, 0.9972837360247222, 0.999255585276937, 0.9949693760216292, 0.9984446919683018, 0.9964372595625972, 0.9982534425422102, 0.9975287575736874, 0.9969345547674652, 0.9977581003920464, 0.996950289211178, 0.9992220884470348, 0.993192930661301, 0.9964753429948073, 0.9951174318100562, 0.9970273459544088, 0.9953927239745392, 0.999499270325093, 0.9972290208465268, 0.9947345658194993, 0.9981187552079898, 0.9964993632332383, 0.996342349402926, 0.9974107620872898, 0.9977181130698499, 0.98706428092911, 0.9891636193774239, 0.03760734550136082, 0.013675398364131208, 0.003418849591032802, 0.9436024871250533, 0.9951166843491107, 0.9958774127553863, 0.9950003738985608, 0.9936256552315994, 0.99561146263638, 0.9961125679438052, 0.9964644893722413, 0.9978859292664787, 0.995357909637259, 0.997350599116685, 0.9935673055336628, 0.9968851016372727, 0.9984648425395217, 0.9964330763577585, 0.9966185980212138, 0.9985867197637597, 0.9997733337904084, 0.9988322778462705, 0.9989810699502061, 0.8551771455243734, 0.14366976044809474, 0.9941612006137279, 0.9963835533394289, 0.9950162567607934, 0.9979016026828111, 0.9977434820204281, 0.9996020225732705, 0.998584203846108, 0.9966573691195548, 0.9966641990818023, 0.9966563855913623, 0.9980965472023693, 0.9953713761245511, 0.9951459800629703, 0.9930721105957052, 0.9979705376790763, 0.9979232619953756, 0.9956851860912208, 0.9920586991504874, 0.9988084423108405, 0.9951960481345975, 0.9970895946454246, 0.998403575220809, 0.9959529129683822, 0.9979754224409889, 0.9965348002581034, 0.9991706281300264, 0.9968883700935878, 0.9933299137713085, 0.9958181412839716, 0.9969887164718155, 0.9996218075686057, 0.9891546404056701, 0.9993233581540153, 0.9978884909831434, 0.9938913792185285, 0.9973774241528174, 0.9963740712458857, 0.9975449501391219, 0.9972639708362636, 0.9976308069589346, 0.9973403046619186, 0.9916055885764602, 0.9972814619267635, 0.9962827357376299, 0.9963086364494439, 0.9922984359413551, 0.9965771061363714, 0.9987089964064693, 0.9989928074325414, 0.9969281204826844, 0.9964353336610735, 0.9990657056688734, 0.9983222691245233, 0.9945574903933446, 0.995127952134128, 0.9968655461660464, 0.9964604930002154, 0.9974886071560671, 0.9940180583209162, 0.992194941066166, 0.9978985846869219, 0.9956314797710686, 0.9977924132548098, 0.9981852721800336, 0.992461524810808, 0.9975492626191675, 0.9964562269645721, 0.994356028515051, 0.9971046946571919, 0.9959380242171615, 0.9960990673117567, 0.9973749193033562, 0.9975506471368807], \"Term\": [\"access\", \"according\", \"active\", \"administered\", \"administers\", \"adults\", \"age\", \"ages\", \"americans\", \"anti\", \"appointment\", \"appointments\", \"april\", \"astrazeneca\", \"australia\", \"available\", \"based\", \"biden\", \"black\", \"blood\", \"canada\", \"cases\", \"cdc\", \"center\", \"centre\", \"check\", \"children\", \"china\", \"city\", \"coming\", \"continue\", \"countries\", \"country\", \"county\", \"cvs\", \"daily\", \"data\", \"day\", \"days\", \"dead\", \"death\", \"deaths\", \"developed\", \"die\", \"died\", \"dies\", \"discharges\", \"disease\", \"doctor\", \"doesn\", \"don\", \"dont\", \"dose\", \"doses\", \"drive\", \"dying\", \"effects\", \"emergency\", \"experts\", \"fake\", \"farm\", \"farm\", \"farm\", \"fight\", \"flu\", \"food\", \"fully\", \"future\", \"getting\", \"global\", \"going\", \"got\", \"government\", \"govt\", \"group\", \"health\", \"here\", \"high\", \"hospitals\", \"hours\", \"immunity\", \"india\", \"indian\", \"infections\", \"jab\", \"johnson\", \"kenyan\", \"know\", \"lack\", \"lakh\", \"latest\", \"laws\", \"laws\", \"laws\", \"laws\", \"life\", \"like\", \"live\", \"long\", \"look\", \"march\", \"mask\", \"masks\", \"mass\", \"million\", \"ministry\", \"moderna\", \"modi\", \"months\", \"mrna\", \"nation\", \"near\", \"need\", \"new\", \"news\", \"news\", \"now\", \"outbreak\", \"oxygen\", \"pandemic\", \"passed\", \"people\", \"pfizer\", \"population\", \"positive\", \"possible\", \"present\", \"public\", \"rate\", \"reactions\", \"read\", \"received\", \"recoveries\", \"reported\", \"reports\", \"research\", \"right\", \"risk\", \"said\", \"saturday\", \"says\", \"second\", \"shot\", \"shots\", \"shows\", \"sick\", \"sign\", \"sites\", \"situation\", \"soon\", \"spike\", \"spread\", \"stand\", \"start\", \"state\", \"states\", \"stop\", \"study\", \"supply\", \"taking\", \"tested\", \"testing\", \"think\", \"time\", \"times\", \"today\", \"toll\", \"total\", \"tough\", \"trials\", \"trump\", \"union\", \"update\", \"use\", \"variants\", \"vax\", \"virus\", \"wait\", \"want\", \"way\", \"wear\", \"weeks\", \"work\", \"workers\", \"world\", \"wrong\", \"year\", \"you\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 3, 2, 6, 5]};\n\nfunction LDAvis_load_lib(url, callback){\n  var s = document.createElement('script');\n  s.src = url;\n  s.async = true;\n  s.onreadystatechange = s.onload = callback;\n  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n  document.getElementsByTagName(\"head\")[0].appendChild(s);\n}\n\nif(typeof(LDAvis) !== \"undefined\"){\n   // already loaded: just create the visualization\n   !function(LDAvis){\n       new LDAvis(\"#\" + \"ldavis_el19731397749451037602771054418\", ldavis_el19731397749451037602771054418_data);\n   }(LDAvis);\n}else if(typeof define === \"function\" && define.amd){\n   // require.js is available: use it to load d3/LDAvis\n   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n   require([\"d3\"], function(d3){\n      window.d3 = d3;\n      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n        new LDAvis(\"#\" + \"ldavis_el19731397749451037602771054418\", ldavis_el19731397749451037602771054418_data);\n      });\n    });\n}else{\n    // require.js not available: dynamically load d3 & LDAvis\n    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n                 new LDAvis(\"#\" + \"ldavis_el19731397749451037602771054418\", ldavis_el19731397749451037602771054418_data);\n            })\n         });\n}\n</script>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "single_plot = pyLDAvis.gensim_models.prepare(single_model, single_corpus, single_dict)\n",
    "single_plot\n"
   ]
  },
  {
   "source": [
    "We can also try building a Mallet LDA model using either parameters identified above or any other parameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n  \n"
     ]
    }
   ],
   "source": [
    "# Download MalletLDA with: wget http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = '/usr/lib/mallet-2.0.8/bin/mallet'\n",
    "mallet_lda = gensim.models.wrappers.LdaMallet(mallet_path=mallet_path, corpus=single_corpus, num_topics=4, alpha='0.6', id2word=single_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(0, '0.046*\"people\" + 0.016*\"virus\" + 0.015*\"anti\" + 0.014*\"dose\" + 0.014*\"fully\" + 0.013*\"pfizer\" + 0.013*\"cdc\" + 0.013*\"risk\" + 0.012*\"variants\" + 0.010*\"doctor\"'), (1, '0.052*\"india\" + 0.035*\"cases\" + 0.034*\"doses\" + 0.015*\"total\" + 0.015*\"health\" + 0.014*\"deaths\" + 0.013*\"million\" + 0.011*\"sputnik\" + 0.011*\"world\" + 0.010*\"news\"'), (2, '0.038*\"emergency\" + 0.032*\"moderna\" + 0.029*\"health\" + 0.028*\"johnson\" + 0.027*\"immunity\" + 0.027*\"usa\" + 0.026*\"wait\" + 0.026*\"fake\" + 0.025*\"die\" + 0.024*\"company\"'), (3, '0.080*\"appointments\" + 0.072*\"sign\" + 0.070*\"cvs\" + 0.028*\"india\" + 0.027*\"age\" + 0.026*\"people\" + 0.022*\"today\" + 0.020*\"modi\" + 0.017*\"group\" + 0.016*\"hospital\"')]\n",
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(mallet_lda.show_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/npodpx/miniconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  \n",
      "0.3216132084984953\n"
     ]
    }
   ],
   "source": [
    "coherence_model_malletlda = CoherenceModel(model=mallet_lda,texts=tweets_nn_lst, dictionary=single_dict, coherence='c_v')\n",
    "coherence_malletlda = coherence_model_malletlda.get_coherence()\n",
    "print(coherence_malletlda)"
   ]
  },
  {
   "source": [
    "Additional things to try? Create bigram and trigram lists as well? Additional models to try? If so, use Gensim.models.phrases and gensim.models.phraser?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Other resources used: https://www.geeksforgeeks.org/python-convert-a-string-representation-of-list-into-list/; https://stackoverflow.com/questions/66759852/no-module-named-pyldavis; http://mallet.cs.umass.edu/download.php; https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/; https://thinkinfi.com/guide-to-build-best-lda-model-using-gensim-python/; https://medium.com/swlh/topic-modeling-lda-mallet-implementation-in-python-part-2-602ffb38d396; https://www.linkedin.com/pulse/nlp-a-complete-guide-topic-modeling-latent-dirichlet-sahil-m/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}